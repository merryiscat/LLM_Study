{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db6ac134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY ì •ë³´ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "728affaa-4038-460e-a234-59b7b09742d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "ì˜ë„ë¶„ë¥˜\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "logging.langsmith(\"ì˜ë„ë¶„ë¥˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6515652-e2c5-43df-95cb-da6ab471ea24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” ì˜ë„ ë¶„ì„ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [14:38<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: intent_classification_full_output.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# 1. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
    "intent_classify_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "ë‹¹ì‹ ì€ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.  \n",
    "ì‚¬ìš©ìê°€ ì•„ë˜ì™€ ê°™ì€ ë‹¨ì–´ë¥¼ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ê²€ìƒ‰í–ˆë‹¤ë©´,  \n",
    "ê·¸ ì‚¬ìš©ìê°€ ì–´ë–¤ ëª©ì ì´ë‚˜ ì˜ë„ë¥¼ ê°€ì§€ê³  ìˆì—ˆëŠ”ì§€ë¥¼ ë¶„ì„í•´ ì£¼ì„¸ìš”.\n",
    "\n",
    "- í‚¤ì›Œë“œëŠ” ë³´í†µ ë‹¨ì–´ë‚˜ ì§§ì€ êµ¬ë¬¸ìœ¼ë¡œ ë˜ì–´ ìˆìœ¼ë©°, ë¬¸ë§¥ì€ ì—†ìŠµë‹ˆë‹¤.\n",
    "- ê°€ëŠ¥í•œ í•œ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ, **ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ìš”ì•½í•œ ì¹´í…Œê³ ë¦¬ ì´ë¦„**ì„ ìƒì„±í•´ ì£¼ì„¸ìš”.\n",
    "- ì´ ì´ë¦„ì€ ë°ì´í„° ë¶„ì„ì´ë‚˜ ë¶„ë¥˜ ì‘ì—…ì—ì„œ ì˜ë„ë¡œ ì“¸ ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "- ê²°ê³¼ëŠ” 5ì~15ì ì´ë‚´ì˜ ì§§ê³  ì§ê´€ì ì¸ í‘œí˜„ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.\n",
    "- ë¶ˆë¶„ëª…í•˜ê±°ë‚˜ ì• ë§¤í•  ê²½ìš°ì—ëŠ” 'ë¶ˆëª…í™•'ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.\n",
    "- ë¹„ìŠ·í•œ ì¹´í…Œê³ ë¦¬ ì´ë¦„ì€ í•˜ë‚˜ë¡œ í†µì¼í•˜ì‹œì˜¤.\n",
    "\n",
    "í˜•ì‹:\n",
    "í‚¤ì›Œë“œ: [í‚¤ì›Œë“œ í…ìŠ¤íŠ¸]  \n",
    "ì˜ë„: [ê°„ë‹¨í•œ ì¹´í…Œê³ ë¦¬ ë˜ëŠ” ì˜ë„ ì´ë¦„]\n",
    "\n",
    "ì˜ˆì‹œ:\n",
    "í‚¤ì›Œë“œ: ì…ì–‘  \n",
    "ì˜ë„: ì‚¬íšŒë³µì§€ ì´ìŠˆ\n",
    "\n",
    "í‚¤ì›Œë“œ: ê¹€ìœ ì‹   \n",
    "ì˜ë„: ì¸ë¬¼ ì •ë³´\n",
    "\n",
    "í‚¤ì›Œë“œ: ì˜ˆì´íšŒê´€  \n",
    "ì˜ë„: ì¥ì†Œ/ì‹œì„¤ ì¡°íšŒ\n",
    "\n",
    "í‚¤ì›Œë“œ: êµ­ë¬´íšŒì˜ë¡  \n",
    "ì˜ë„: í–‰ì • ê¸°ë¡ ì—´ëŒ\n",
    "\n",
    "---\n",
    "\n",
    "ë‹¤ìŒ í‚¤ì›Œë“œì— ëŒ€í•´ ì‚¬ìš©ìì˜ ê²€ìƒ‰ ì˜ë„ë¥¼ ì¶”ë¡ í•´ ì£¼ì„¸ìš”:\n",
    "{user_input}\n",
    "\"\"\")\n",
    "\n",
    "# 2. LLM ëª¨ë¸ ì„¤ì •\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# 3. ì‘ë‹µ íŒŒì‹± í•¨ìˆ˜ ì •ì˜\n",
    "def parse_intent_from_text(text: str) -> str:\n",
    "    try:\n",
    "        for line in text.split(\"\\n\"):\n",
    "            if line.strip().startswith(\"ì˜ë„:\"):\n",
    "                return line.split(\"ì˜ë„:\")[1].strip()\n",
    "    except:\n",
    "        pass\n",
    "    return \"ì—ëŸ¬\"\n",
    "\n",
    "# 4. íŒŒì„œì™€ ì²´ì¸ êµ¬ì„±\n",
    "parser = RunnableLambda(lambda x: type(\"Obj\", (), {\"intent\": parse_intent_from_text(x.content)}))\n",
    "intent_classify_chain = intent_classify_prompt | llm | parser\n",
    "\n",
    "# 5. ì—‘ì…€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "input_file = \"keyword_log.xlsx\"\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "# 6. LLMìœ¼ë¡œ í‚¤ì›Œë“œ ì˜ë„ ì¶”ë¡ \n",
    "predicted_intents = []\n",
    "\n",
    "for keyword in tqdm(df[\"KEYWORD\"], desc=\"ğŸ” ì˜ë„ ë¶„ì„ ì¤‘\"):\n",
    "    try:\n",
    "        output = intent_classify_chain.invoke({\"user_input\": keyword})\n",
    "        predicted_intents.append(output.intent)\n",
    "    except Exception as e:\n",
    "        print(f\"[ì—ëŸ¬] {keyword}: {e}\")\n",
    "        predicted_intents.append(\"ì—ëŸ¬\")\n",
    "\n",
    "# 7. ê²°ê³¼ ì¶”ê°€ ë° ì €ì¥\n",
    "df[\"predicted_intent\"] = predicted_intents\n",
    "\n",
    "output_file = \"intent_classification_full_output.xlsx\"\n",
    "df.to_excel(output_file, index=False)\n",
    "print(f\"\\nâœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d890df0-1d7d-4295-8823-6c71f5d31f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from collections import Counter\n",
    "\n",
    "# ğŸ”§ 1. ì„¤ì •\n",
    "train_csv_path = \"train.csv\"  # í•™ìŠµì…‹ (text, label í¬í•¨ CSV)\n",
    "test_excel_path = \"keyword_log_all.xlsx\"  # 46,000ê±´ í‚¤ì›Œë“œ\n",
    "output_file = \"knn_prediction_46000_optimized.xlsx\"\n",
    "embedding_model_name = \"intfloat/multilingual-e5-large\"\n",
    "\n",
    "# âœ… 2. ëª¨ë¸ ë¡œë“œ\n",
    "print(\"ğŸ”„ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
    "embedding_model = SentenceTransformer(embedding_model_name)\n",
    "\n",
    "# âœ… 3. í•™ìŠµ ë°ì´í„° ë¡œë”©\n",
    "print(\"ğŸ“¥ í•™ìŠµ ë°ì´í„° ë¡œë”© ì¤‘...\")\n",
    "df_train = pd.read_csv(train_csv_path)\n",
    "train_sentences = df_train[\"text\"].astype(str).tolist()\n",
    "train_labels = df_train[\"label\"].tolist()\n",
    "\n",
    "# âœ… 4. í•™ìŠµ ë¬¸ì¥ ì„ë² ë”©\n",
    "print(\"ğŸ“Œ í•™ìŠµ ë¬¸ì¥ ì„ë² ë”© ì¤‘...\")\n",
    "train_vectors = embedding_model.encode(train_sentences, convert_to_numpy=True, normalize_embeddings=True)\n",
    "\n",
    "# âœ… 5. Faiss ì¸ë±ìŠ¤ êµ¬ì„±\n",
    "print(\"ğŸ” Faiss ì¸ë±ìŠ¤ ìƒì„± ì¤‘...\")\n",
    "dim = train_vectors.shape[1]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(train_vectors)\n",
    "\n",
    "# âœ… 6. í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”©\n",
    "print(\"ğŸ“¥ í…ŒìŠ¤íŠ¸ í‚¤ì›Œë“œ ë¡œë”© ì¤‘...\")\n",
    "df_test = pd.read_excel(test_excel_path)\n",
    "test_keywords = df_test[\"KEYWORD\"].astype(str).tolist()\n",
    "\n",
    "# âœ… 7. í…ŒìŠ¤íŠ¸ í‚¤ì›Œë“œ ì„ë² ë”©\n",
    "print(\"ğŸ“Œ í…ŒìŠ¤íŠ¸ í‚¤ì›Œë“œ ì„ë² ë”© ì¤‘...\")\n",
    "test_vectors = embedding_model.encode(test_keywords, convert_to_numpy=True, normalize_embeddings=True)\n",
    "\n",
    "# âœ… 8. Faiss ê²€ìƒ‰\n",
    "print(\"ğŸ” KNN ê²€ìƒ‰ ì¤‘...\")\n",
    "k = 10\n",
    "distances, indices = index.search(test_vectors, k)\n",
    "\n",
    "# âœ… 9. ë‹¤ìˆ˜ê²°ë¡œ ì˜ˆì¸¡ ë¼ë²¨ ìƒì„±\n",
    "print(\"ğŸ§  ë‹¤ìˆ˜ê²° ì˜ˆì¸¡ ì¤‘...\")\n",
    "predicted_labels = []\n",
    "for i in tqdm(range(len(test_keywords))):\n",
    "    knn_labels = [train_labels[j] for j in indices[i]]\n",
    "    pred_label = Counter(knn_labels).most_common(1)[0][0]\n",
    "    predicted_labels.append(pred_label)\n",
    "\n",
    "# âœ… 10. ê²°ê³¼ ì €ì¥\n",
    "df_test[\"predicted_intent_knn\"] = predicted_labels\n",
    "df_test.to_excel(output_file, index=False)\n",
    "print(f\"\\nâœ… ì™„ë£Œ! ê²°ê³¼ ì €ì¥ë¨: {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
