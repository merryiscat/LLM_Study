{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07111a4b-d40c-4995-99c2-1cd7d2089c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (1.1.6)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: langgraph in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (1.0.5)\n",
      "Requirement already satisfied: langchain-chroma in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: chromadb in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (1.3.7)\n",
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.26.7-cp310-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.1 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from langchain) (1.2.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from langchain) (2.12.5)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from langgraph) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from langgraph) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from langgraph) (0.3.1)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.5.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.1)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from langchain-openai) (2.14.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (1.3.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
      "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
      "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting SQLAlchemy<3.0.0,>=1.4.0 (from langchain-community)\n",
      "  Downloading sqlalchemy-2.0.45-cp310-cp310-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.13.2-cp310-cp310-win_amd64.whl.metadata (8.4 kB)\n",
      "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community)\n",
      "  Using cached pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from langchain-community) (2.2.6)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading frozenlist-1.8.0-cp310-cp310-win_amd64.whl.metadata (21 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading multidict-6.7.0-cp310-cp310-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading propcache-0.4.1-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading yarl-1.22.0-cp310-cp310-win_amd64.whl.metadata (77 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
      "  Downloading langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (2.3.0)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community)\n",
      "  Downloading greenlet-3.3.0-cp310-cp310-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from chromadb) (1.3.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from chromadb) (1.4.3)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from chromadb) (1.23.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from chromadb) (1.39.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from chromadb) (0.22.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from chromadb) (1.76.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from chromadb) (5.0.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from chromadb) (0.20.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from chromadb) (34.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from chromadb) (4.1.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from chromadb) (14.2.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from chromadb) (4.25.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: tomli>=1.1.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from build>=1.0.3->chromadb) (2.2.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.28.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.45.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (6.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
      "Requirement already satisfied: protobuf in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (6.33.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.39.1 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.60b1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (1.2.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.20.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.12.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.2.0)\n",
      "Requirement already satisfied: shellingham in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (0.20.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.3.1)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dique\\miniconda3\\envs\\ml\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 24.2 MB/s  0:00:00\n",
      "Downloading aiohttp-3.13.2-cp310-cp310-win_amd64.whl (455 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
      "Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 25.1 MB/s  0:00:00\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.7.0-cp310-cp310-win_amd64.whl (46 kB)\n",
      "Using cached pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
      "Downloading sqlalchemy-2.0.45-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 30.2 MB/s  0:00:00\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.22.0-cp310-cp310-win_amd64.whl (86 kB)\n",
      "Downloading pymupdf-1.26.7-cp310-abi3-win_amd64.whl (18.4 MB)\n",
      "   ---------------------------------------- 0.0/18.4 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 8.7/18.4 MB 44.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 16.3/18.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.4/18.4 MB 37.5 MB/s  0:00:00\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.8.0-cp310-cp310-win_amd64.whl (43 kB)\n",
      "Downloading greenlet-3.3.0-cp310-cp310-win_amd64.whl (300 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading propcache-0.4.1-cp310-cp310-win_amd64.whl (41 kB)\n",
      "Installing collected packages: pymupdf, propcache, mypy-extensions, multidict, marshmallow, httpx-sse, greenlet, frozenlist, async-timeout, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain-text-splitters, langchain-classic, langchain-community\n",
      "\n",
      "   ----------------------------------------  0/20 [pymupdf]\n",
      "   ----------------------------------------  0/20 [pymupdf]\n",
      "   ----------------------------------------  0/20 [pymupdf]\n",
      "   -------- -------------------------------  4/20 [marshmallow]\n",
      "   ------------ ---------------------------  6/20 [greenlet]\n",
      "   -------------------- ------------------- 10/20 [yarl]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------------ --------- 15/20 [dataclasses-json]\n",
      "   -------------------------------- ------- 16/20 [aiohttp]\n",
      "   -------------------------------- ------- 16/20 [aiohttp]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   ---------------------------------------- 20/20 [langchain-community]\n",
      "\n",
      "Successfully installed SQLAlchemy-2.0.45 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 async-timeout-4.0.3 dataclasses-json-0.6.7 frozenlist-1.8.0 greenlet-3.3.0 httpx-sse-0.4.3 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-text-splitters-1.1.0 marshmallow-3.26.1 multidict-6.7.0 mypy-extensions-1.1.0 propcache-0.4.1 pydantic-settings-2.12.0 pymupdf-1.26.7 typing-inspect-0.9.0 yarl-1.22.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install -U \\\n",
    "    langchain \\\n",
    "    langchain-openai \\\n",
    "    langchain-community \\\n",
    "    langgraph \\\n",
    "    langchain-chroma \\\n",
    "    chromadb \\\n",
    "    pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66aeb681-0452-4b25-a9fd-e24a5ed844d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY ì •ë³´ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6603e3ad-26d9-4388-8553-42d9946855e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "ì£¼ì‹ë¶„ì„\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "logging.langsmith(\"ì£¼ì‹ë¶„ì„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d675de64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryLoop:\n",
    "    def __init__(self, query_list):\n",
    "        self.queries = query_list\n",
    "        self.index = 0\n",
    "        self.results = {}\n",
    "        self.fallback_queries = []\n",
    "\n",
    "    def has_next(self):\n",
    "        return self.index < len(self.queries)\n",
    "\n",
    "    def next_query(self):\n",
    "        return self.queries[self.index]\n",
    "\n",
    "    def save_result(self, query_key, result_dict):\n",
    "        self.results[query_key] = result_dict\n",
    "        self.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa766e47-1da0-4d73-bd79-86ef18cb17cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Annotated, List, Dict\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.messages import HumanMessage, ToolMessage, AIMessage\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import create_retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "053180a3-c4cf-4e3c-a1df-9c9dea6a0184",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## states ì •ì˜ ########\n",
    "class InputState(TypedDict):\n",
    "    start_input: str\n",
    "\n",
    "class OverallState(TypedDict):\n",
    "    user_input: str\n",
    "    messages: Annotated[list, add_messages]\n",
    "    Stock_Value_dict: dict\n",
    "    query_list: List[str]\n",
    "\n",
    "class EndState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    query_list: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5299c4dd-a103-4a39-af77-78f9f74fdd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ìš©ì ì…ë ¥ ë…¸ë“œ ì •ì˜\n",
    "def user_input_node(state: InputState):\n",
    "    print(\"================================= calculation stock =================================\")\n",
    "    print(\"ì£¼ì‹ ê°€ì¹˜ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. ì‚¼ì„±ì „ì ì…ë ¥\")\n",
    "    user_input = input(\"User: \")\n",
    "\n",
    "    return {\n",
    "        \"user_input\": user_input,\n",
    "        \"messages\": [(\"user\", user_input)],\n",
    "        \"Stock_Value_dict\": {},  # ë‚˜ì¤‘ì— ì—¬ê¸°ì— ë°ì´í„° ì±„ì›Œì§\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09d5d5a5-69a0-4ded-8007-1a5b15803893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_query_generation_node(state: OverallState):\n",
    "    user_input = state[\"user_input\"]\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ê¸ˆìœµ ì •ë³´ë¥¼ ì°¾ê¸° ìœ„í•œ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\"),\n",
    "        (\"human\", '''\n",
    "ì‚¬ìš©ì ì…ë ¥: \"{user_input}\"ì„ ì°¸ê³ í•˜ì—¬ ì•„ë˜ ë‚´ìš©ì— ëŒ€í•´ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.\n",
    "  \"ë‹¹ê¸°ìˆœì´ìµ\",\n",
    "  \"ë°œí–‰ì£¼ì‹ìˆ˜\",\n",
    "  \"í˜„ì¬ ì£¼ê°€\",\n",
    "  \"ìë³¸ì´ê³„\",\n",
    "  \"ììœ í˜„ê¸ˆíë¦„\",\n",
    "  \"ì˜ì—…ì´ìµ\",\n",
    "  \"ê°€ì¤‘í‰ê· ìë³¸ë¹„ìš©(WACC)\",\n",
    "  \"ì˜ˆìƒë¯¸ë˜í˜„ê¸ˆíë¦„\",\n",
    "  \"ì„±ì¥ë¥ \",\n",
    "  \"ì£¼ë‹¹ë°°ë‹¹ê¸ˆ\",\n",
    "  \"ê¸°íƒ€ ìˆ˜ìµ ê´€ë ¨ ì •ë³´\"\n",
    "ì¶œë ¥ í˜•ì‹ì€ ë°˜ë“œì‹œ JSON ë°°ì—´ì…ë‹ˆë‹¤. \n",
    "''')\n",
    "    ])\n",
    "\n",
    "    messages = prompt.format_messages(user_input=user_input)\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    try:\n",
    "        cleaned = re.sub(r\"^```(?:json)?\\n|\\n```$\", \"\", response.content.strip())\n",
    "        query_list = json.loads(cleaned)\n",
    "    except Exception as e:\n",
    "        print(f\"â— ê²€ìƒ‰ ì¿¼ë¦¬ íŒŒì‹± ì‹¤íŒ¨: {e}\")\n",
    "        query_list = []\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"query_list\": query_list\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d91186b6-f6a4-4b8f-977e-bfdd3ec9fb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_refine_node(state: dict) -> dict:\n",
    "    original_queries = state.get(\"query_list\", [])\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "\n",
    "    # ğŸ”¹ few-shot ì˜ˆì‹œ\n",
    "    examples = [\n",
    "        {\n",
    "            \"input\": [\"ì‚¼ì„±ì „ì ë‹¹ê¸°ìˆœì´ìµ\", \"ì‚¼ì„±ì „ì ë°œí–‰ì£¼ì‹ìˆ˜\"],\n",
    "            \"output\": [\"ì‚¼ì„±ì „ì 2025ë…„ ì—°ê²° ê¸°ì¤€ ë‹¹ê¸°ìˆœì´ìµ\", \"ì‚¼ì„±ì „ì 2025ë…„ ë°œí–‰ì£¼ì‹ìˆ˜\"]\n",
    "        },\n",
    "        {\n",
    "            \"input\": [\"LGì—ë„ˆì§€ì†”ë£¨ì…˜ ì˜ì—…ì´ìµ\", \"LGì—ë„ˆì§€ì†”ë£¨ì…˜ ì„±ì¥ë¥ \"],\n",
    "            \"output\": [\"LGì—ë„ˆì§€ì†”ë£¨ì…˜ 2025ë…„ ì—°ê²° ê¸°ì¤€ ì˜ì—…ì´ìµ\", \"LGì—ë„ˆì§€ì†”ë£¨ì…˜ 2025ë…„ ì˜ˆìƒ ì„±ì¥ë¥ \"]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    few_shot_format = \"\\n\\n\".join([\n",
    "        f\"ì…ë ¥: {ex['input']}\\në³´ì • ê²°ê³¼: {ex['output']}\"\n",
    "        for ex in examples\n",
    "    ])\n",
    "\n",
    "    # âœ… í”„ë¡¬í”„íŠ¸ ì •ì˜\n",
    "    refine_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", f\"\"\"\n",
    "ë‹¹ì‹ ì€ ê¸°ì—…ì˜ ê³µì‹œ ë³´ê³ ì„œë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ ì¿¼ë¦¬ë¥¼ ì •ì œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì‚¬ìš©ìê°€ ì œê³µí•œ ì¿¼ë¦¬ëŠ” ë‹¤ì†Œ ì¼ë°˜ì ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ,\n",
    "í•´ë‹¹ í•­ëª©ì´ ê¸°ì—… ë³´ê³ ì„œ ìƒ ì‹¤ì œ ë¬¸ë‹¨ ì œëª©, í‘œ ì œëª©, í•­ëª©ëª…ì— ë” ì˜ ë§¤ì¹­ë˜ë„ë¡\n",
    "ì •í™•í•˜ê³  ëª…í™•í•˜ê²Œ ë³´ì •í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ì˜ˆì‹œ few-shot:\n",
    "{few_shot_format}\n",
    "\n",
    "ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì¿¼ë¦¬ ëª©ë¡ì…ë‹ˆë‹¤:\n",
    "{{query_list}}\n",
    "\n",
    "ê°€ëŠ¥í•˜ë©´ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ ì´ìƒì˜ ê¸°ì¤€ì„ ë°˜ì˜í•˜ì„¸ìš”:\n",
    "- \"ìš”ì•½ ì¬ë¬´ì œí‘œ\", \"ì§€ë°°ê¸°ì—… ì†Œìœ ì£¼\", \"ì—°ê²° ì†ìµê³„ì‚°ì„œ\", \"í˜„ê¸ˆíë¦„í‘œ\" ê°™ì€ ì‹¤ì œ ì¬ë¬´í‘œ ì œëª©ì„ í¬í•¨\n",
    "- ìˆ˜ì¹˜ê°€ í¬í•¨ëœ í‘œë‚˜ ë¬¸ë‹¨ê³¼ ì§ì ‘ ë§¤ì¹­ë˜ëŠ” ëª…í™•í•œ í‚¤ì›Œë“œ ì‚¬ìš©\n",
    "- ë„ˆë¬´ ì¼ë°˜ì ì¸ í‘œí˜„(ì˜ˆ: 'ìˆœì´ìµ') ëŒ€ì‹  ê³µì‹ ëª…ì¹­(ì˜ˆ: 'ê·€ì† ì†ìµ') ì‚¬ìš©\n",
    "\n",
    "ì•„ë˜ì— JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œ ë³´ì •ëœ ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n",
    "ì˜ˆ: [\"...\", \"...\"]\n",
    "\"\"\")\n",
    "    ])\n",
    "\n",
    "    # âœ… í”„ë¡¬í”„íŠ¸ ë©”ì‹œì§€ ìƒì„±\n",
    "    messages = refine_prompt.format_messages(\n",
    "        query_list=json.dumps(original_queries, ensure_ascii=False)\n",
    "    )\n",
    "\n",
    "    # âœ… LLM í˜¸ì¶œ\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    # âœ… ì‘ë‹µ ì²˜ë¦¬\n",
    "    try:\n",
    "        cleaned = re.sub(r\"^```(?:json)?\\n|\\n```$\", \"\", response.content.strip())\n",
    "        refined_queries = json.loads(cleaned)\n",
    "\n",
    "        if not isinstance(refined_queries, list):\n",
    "            raise ValueError(\"ë³´ì • ê²°ê³¼ê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹˜\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"â— ì¿¼ë¦¬ ë³´ì • ì‹¤íŒ¨: {e}\")\n",
    "        refined_queries = original_queries\n",
    "\n",
    "    # ğŸ” ë¡œê·¸ ì¶œë ¥\n",
    "    print(\"\\nğŸ” ì¿¼ë¦¬ ë³´ì • ê²°ê³¼:\")\n",
    "    for o, r in zip(original_queries, refined_queries):\n",
    "        print(f\"- {o} â†’ {r}\")\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"query_list\": refined_queries,\n",
    "        \"previous_query\": original_queries,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6ad462f-65ed-48f6-8f53-833584a16a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë³¸ ë¬¸ì„œ ìˆ˜: 404\n",
      "ì¤‘ë³µ ì œê±° í›„ ë¬¸ì„œ ìˆ˜: 403\n"
     ]
    }
   ],
   "source": [
    "######## nodes.py ########\n",
    "# --- ë¬¸ì„œ ë¡œë“œ ë° ì „ì²˜ë¦¬ ---\n",
    "loader = PyMuPDFLoader(\"stock_report/[ì‚¼ì„±ì „ì]ë¶„ê¸°ë³´ê³ ì„œ(2024.11.14).pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "## : ë¬¸ì„œ ë¶„í• (Split Documents) <-----------ì¶”í›„ ë¬¸ì„œ ì œëª© ë‹¨ìœ„ ë¶„í• ë¡œ ë³€ê²½ í•„ìš”\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=500)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# ì¤‘ë³µ ì œê±°\n",
    "unique_documents = []\n",
    "seen_contents = set()\n",
    "\n",
    "for doc in split_documents:\n",
    "    content = doc.page_content.strip()\n",
    "    if content not in seen_contents:\n",
    "        seen_contents.add(content)\n",
    "        unique_documents.append(doc)\n",
    "\n",
    "print(f\"ì›ë³¸ ë¬¸ì„œ ìˆ˜: {len(split_documents)}\")\n",
    "print(f\"ì¤‘ë³µ ì œê±° í›„ ë¬¸ì„œ ìˆ˜: {len(unique_documents)}\")\n",
    "\n",
    "## ë‹¨ê³„ 3: ì„ë² ë”©(Embedding) ìƒì„±\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# ë²¡í„°ìŠ¤í† ì–´ ìƒì„±\n",
    "vectorstore = Chroma.from_documents(documents=split_documents, embedding=embeddings, persist_directory=\"stock_report/chroma_db\")\n",
    "\n",
    "# 5. ê²€ìƒ‰ê¸°(Retriever) ìƒì„±\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20eb4170-a4d2-48ab-9769-59ad14c08fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_mapping = {\n",
    "    \"ë‹¹ê¸°ìˆœì´ìµ\": \"Net_Income\",\n",
    "    \"ë°œí–‰ì£¼ì‹ìˆ˜\": \"Shares_Outstanding\",\n",
    "    \"í˜„ì¬ ì£¼ê°€\": \"Stock_Price\",\n",
    "    \"ìë³¸ì´ê³„\": \"Shareholders_equity\",\n",
    "    \"ììœ í˜„ê¸ˆíë¦„\": \"Free_cash_flow\",\n",
    "    \"ì˜ì—…ì´ìµ\": \"Operating_income\",\n",
    "    \"ê°€ì¤‘í‰ê· ìë³¸ë¹„ìš©\": \"WACC\",\n",
    "    \"ì˜ˆìƒë¯¸ë˜í˜„ê¸ˆíë¦„\": \"Projected_future_cash_flows\",\n",
    "    \"ì„±ì¥ë¥ \": \"Growth_Rate\",\n",
    "    \"ì£¼ë‹¹ë°°ë‹¹ê¸ˆ\": \"Dividend_per_share\",\n",
    "    \"ê¸°íƒ€ ìˆ˜ìµ ê´€ë ¨ ì •ë³´\": \"Other_return_related_information\",\n",
    "}\n",
    "\n",
    "summary_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "ë‹¹ì‹ ì€ ê¸°ì—…ì˜ ì¬ë¬´ ì •ë³´ë¥¼ ìš”ì•½í•˜ëŠ” ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "ë‹¤ìŒ ë¬¸ì„œë¥¼ ì½ê³ , ì•„ë˜ í•­ëª©ì— ëŒ€í•´ **ì •í™•í•œ ê°’ê³¼ ë‹¨ìœ„**ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.\n",
    "\n",
    "ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš” (JSON):\n",
    "{{\n",
    "  \"ë‹¹ê¸°ìˆœì´ìµ\": \"...\",\n",
    "  \"ë°œí–‰ì£¼ì‹ìˆ˜\": \"...\",\n",
    "  \"í˜„ì¬ ì£¼ê°€\": \"...\",\n",
    "  \"ìë³¸ì´ê³„\": \"...\",\n",
    "  \"ììœ í˜„ê¸ˆíë¦„\": \"...\",\n",
    "  \"ì˜ì—…ì´ìµ\": \"...\",\n",
    "  \"ê°€ì¤‘í‰ê· ìë³¸ë¹„ìš©(WACC)\": \"...\",\n",
    "  \"ì˜ˆìƒë¯¸ë˜í˜„ê¸ˆíë¦„\": \"...\",\n",
    "  \"ì„±ì¥ë¥ \": \"...\",\n",
    "  \"ì£¼ë‹¹ë°°ë‹¹ê¸ˆ\": \"...\",\n",
    "  \"ê¸°íƒ€ ìˆ˜ìµ ê´€ë ¨ ì •ë³´\": \"...\"\n",
    "}}\n",
    "\n",
    "ê°’ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë¬¸ì„œì— ëª…í™•íˆ ì—†ìœ¼ë©´ \"ì—†ìŒ\"ì´ë¼ê³  í‘œê¸°í•˜ì„¸ìš”.\n",
    "\"\"\"),\n",
    "    (\"human\", \"{context}\")\n",
    "])\n",
    "\n",
    "def summarize_context(context: str, llm) -> dict:\n",
    "    messages = summary_prompt.format_messages(context=context)\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    try:\n",
    "        raw = re.sub(r\"^```(?:json)?\\n|\\n```$\", \"\", response.content.strip())\n",
    "        parsed = json.loads(raw)\n",
    "        return {key_mapping.get(k, k): v for k, v in parsed.items()}\n",
    "    except Exception as e:\n",
    "        print(f\"â— ìš”ì•½ íŒŒì‹± ì‹¤íŒ¨: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dd20d91-7758-4168-8e82-072ca9eeb76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(parsed: dict, stock_data: dict):\n",
    "    for k, v in parsed.items():\n",
    "        if k not in stock_data or stock_data[k] == \"ì—†ìŒ\":\n",
    "            stock_data[k] = v\n",
    "\n",
    "def query_loop_node(state: OverallState) -> OverallState:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    tavily = TavilySearchResults(max_results=3)\n",
    "\n",
    "    stock_data = {}\n",
    "    fallback_queries = []\n",
    "    key_fields_to_check = [\"Net_Income\", \"Operating_income\", \"Free_cash_flow\"]\n",
    "\n",
    "    for query in state[\"query_list\"]:\n",
    "        print(f\"\\nğŸ” [RAG ê²€ìƒ‰] {query}\")\n",
    "\n",
    "        try:\n",
    "            docs = list({doc.page_content.strip() for doc in retriever.invoke(query)})\n",
    "            context = \"\\n\\n\".join(docs)[:3000]\n",
    "        except Exception as e:\n",
    "            print(f\"â— RAG ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            context = \"\"\n",
    "\n",
    "        parsed = summarize_context(context, llm)\n",
    "\n",
    "        if all(parsed.get(k, \"ì—†ìŒ\") == \"ì—†ìŒ\" for k in key_fields_to_check):\n",
    "            print(\"âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\")\n",
    "            fallback_queries.append(query)\n",
    "\n",
    "            try:\n",
    "                web_result = tavily.invoke({\"query\": query})\n",
    "\n",
    "                # âœ… ì›¹ ê²°ê³¼ê°€ listì¸ì§€ í™•ì¸\n",
    "                if isinstance(web_result, list):\n",
    "                    web_context = \"\\n\\n\".join([doc.get(\"content\", \"\") for doc in web_result])[:3000]\n",
    "                else:\n",
    "                    web_context = \"\\n\\n\".join([doc.get(\"content\", \"\") for doc in web_result.get(\"documents\", [])])[:3000]\n",
    "\n",
    "                if web_context.strip():\n",
    "                    parsed = summarize_context(web_context, llm)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"â— ì›¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "        # regardless of source (RAG or web), merge\n",
    "        merge(parsed, stock_data)\n",
    "\n",
    "    # ëˆ„ë½ëœ í•­ëª© \"ì—†ìŒ\" ì±„ìš°ê¸°\n",
    "    for key in key_mapping.values():\n",
    "        if key not in stock_data:\n",
    "            stock_data[key] = \"ì—†ìŒ\"\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"Stock_Value_dict\": stock_data,\n",
    "        \"fallback_queries\": fallback_queries,\n",
    "        \"messages\": state[\"messages\"] + [AIMessage(content=\"âœ… í•µì‹¬ í‚¤ ê¸°ì¤€ RAG + ì›¹ fallback ì™„ë£Œ\")],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2600323d-7771-450b-8667-8d92b8213bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_fallback_node(state: OverallState) -> OverallState:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    web = TavilySearchResults(max_results=3)\n",
    "    stock_data = state[\"Stock_Value_dict\"]\n",
    "    fallback_queries = state.get(\"fallback_queries\", [])\n",
    "\n",
    "    for query in fallback_queries:\n",
    "        print(f\"ğŸŒ [ì›¹ ê²€ìƒ‰ fallback] {query}\")\n",
    "        web_result = web.invoke({\"query\": query})\n",
    "        web_context = \"\\n\\n\".join([d[\"content\"] for d in web_result[\"documents\"]])[:3000]\n",
    "        parsed = summarize_context(web_context, llm)\n",
    "        merge(parsed, stock_data)\n",
    "\n",
    "    return {\n",
    "        \"Stock_Value_dict\": stock_data,\n",
    "        \"messages\": state[\"messages\"] + [AIMessage(content=\"ğŸŒ ì›¹ ê²€ìƒ‰ ë³´ì™„ ì™„ë£Œ\")],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ef906d5-a030-4cb8-a7dc-fee97ae0c514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_valuation_node(state: OverallState) -> OverallState:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    financials = state.get(\"Stock_Value_dict\", {})\n",
    "    user_input = state.get(\"user_input\", \"\")\n",
    "\n",
    "    valuation_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"\n",
    "ë‹¹ì‹ ì€ ê¸°ì—…ì˜ ì¬ë¬´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°€ì¹˜ë¥¼ í‰ê°€í•˜ëŠ” ê¸ˆìœµ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ìŒ ì¬ë¬´ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **ì‚¼ì„±ì „ìì˜ ì£¼ì‹ ê°€ì¹˜ë¥¼ ì¶”ì •**í•´ ì£¼ì„¸ìš”.\n",
    "- ê°€ëŠ¥í•˜ë©´ **ììœ í˜„ê¸ˆíë¦„ í• ì¸ë²•(DCF)** ëª¨ë¸ì„ ì‚¬ìš©í•˜ê³ , \n",
    "- **PER/PBR** ê¸°ë°˜ì˜ ë³´ì™„ì  ê³„ì‚°ë„ í•¨ê»˜ ì§„í–‰í•´ ì£¼ì„¸ìš”.\n",
    "\n",
    "ì¶œë ¥ì€ ë‹¤ìŒ í˜•ì‹ì„ ë”°ë¦…ë‹ˆë‹¤:\n",
    "\n",
    "---\n",
    "1. ì‚¬ìš©ëœ ì£¼ìš” ì¬ë¬´ ì§€í‘œ ìš”ì•½\n",
    "2. [DCF] ë°©ì‹ì— ì˜í•œ ì£¼ë‹¹ ì ì • ì£¼ê°€ ì¶”ì •\n",
    "3. [PER/PBR] ë°©ì‹ì— ì˜í•œ ì£¼ë‹¹ ì ì • ì£¼ê°€ ì¶”ì •\n",
    "4. ìµœì¢… íŒë‹¨ ë° íˆ¬ìì ì°¸ê³  ì‚¬í•­\n",
    "\n",
    "ë°ì´í„°:\n",
    "{financials}\n",
    "\"\"\"),\n",
    "        (\"human\", f\"{user_input}ì˜ ì£¼ì‹ ê°€ì¹˜ë¥¼ í‰ê°€í•´ì¤˜.\")\n",
    "    ])\n",
    "\n",
    "    messages = valuation_prompt.format_messages(financials=json.dumps(financials, ensure_ascii=False))\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    print(\"\\nğŸ“ˆ ì£¼ì‹ ê°€ì¹˜ í‰ê°€ ê²°ê³¼:\")\n",
    "    print(response.content.strip())\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"valuation_result\": response.content.strip(),\n",
    "        \"messages\": state[\"messages\"] + [AIMessage(content=\"ğŸ“ˆ ì£¼ì‹ ê°€ì¹˜ í‰ê°€ ì™„ë£Œ\")]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a789c71d-1742-4c8d-81a2-619a6bc789ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dique\\AppData\\Local\\Temp\\ipykernel_10000\\1815346823.py:3: LangGraphDeprecatedSinceV05: `input` is deprecated and will be removed. Please use `input_schema` instead. Deprecated in LangGraph V0.5 to be removed in V2.0.\n",
      "  graph_builder = StateGraph(OverallState, input=InputState, output=EndState)\n",
      "C:\\Users\\dique\\AppData\\Local\\Temp\\ipykernel_10000\\1815346823.py:3: LangGraphDeprecatedSinceV05: `output` is deprecated and will be removed. Please use `output_schema` instead. Deprecated in LangGraph V0.5 to be removed in V2.0.\n",
      "  graph_builder = StateGraph(OverallState, input=InputState, output=EndState)\n"
     ]
    }
   ],
   "source": [
    "# ë©”ëª¨ë¦¬ ë° ìƒíƒœ ê·¸ë˜í”„ ì´ˆê¸°í™”\n",
    "memory = MemorySaver()\n",
    "graph_builder = StateGraph(OverallState, input=InputState, output=EndState)\n",
    "\n",
    "# ë…¸ë“œ ë“±ë¡\n",
    "graph_builder.add_node(\"User Input\", user_input_node)\n",
    "graph_builder.add_node(\"Search Query Generation\", search_query_generation_node)\n",
    "graph_builder.add_node(\"Query Refinement\", query_refine_node)\n",
    "graph_builder.add_node(\"Query Loop (RAG + Web)\", query_loop_node)\n",
    "graph_builder.add_node(\"Web Fallback\", web_fallback_node)\n",
    "graph_builder.add_node(\"Stock Valuation\", stock_valuation_node)\n",
    "\n",
    "# ì—£ì§€ ì—°ê²°\n",
    "graph_builder.set_entry_point(\"User Input\")  # ì‹œì‘ ë…¸ë“œ\n",
    "graph_builder.add_edge(\"User Input\", \"Search Query Generation\")\n",
    "graph_builder.add_edge(\"Search Query Generation\", \"Query Refinement\")\n",
    "graph_builder.add_edge(\"Query Refinement\", \"Query Loop (RAG + Web)\")\n",
    "graph_builder.add_edge(\"Query Loop (RAG + Web)\", \"Stock Valuation\")\n",
    "graph_builder.add_edge(\"Stock Valuation\", END)\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9ad7c1b-9fd2-4119-988d-8bcbc004f8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================= calculation stock =================================\n",
      "ì£¼ì‹ ê°€ì¹˜ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. ì‚¼ì„±ì „ì ì…ë ¥\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  ì‚¼ì„±ì „ì\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” ì¿¼ë¦¬ ë³´ì • ê²°ê³¼:\n",
      "- ì‚¼ì„±ì „ì ë‹¹ê¸°ìˆœì´ìµ â†’ ì‚¼ì„±ì „ì 2025ë…„ ì—°ê²° ê¸°ì¤€ ë‹¹ê¸°ìˆœì´ìµ\n",
      "- ì‚¼ì„±ì „ì ë°œí–‰ì£¼ì‹ìˆ˜ â†’ ì‚¼ì„±ì „ì 2025ë…„ ë°œí–‰ì£¼ì‹ìˆ˜\n",
      "- ì‚¼ì„±ì „ì í˜„ì¬ ì£¼ê°€ â†’ ì‚¼ì„±ì „ì 2025ë…„ í˜„ì¬ ì£¼ê°€\n",
      "- ì‚¼ì„±ì „ì ìë³¸ì´ê³„ â†’ ì‚¼ì„±ì „ì 2025ë…„ ì—°ê²° ê¸°ì¤€ ìë³¸ì´ê³„\n",
      "- ì‚¼ì„±ì „ì ììœ í˜„ê¸ˆíë¦„ â†’ ì‚¼ì„±ì „ì 2025ë…„ ììœ í˜„ê¸ˆíë¦„\n",
      "- ì‚¼ì„±ì „ì ì˜ì—…ì´ìµ â†’ ì‚¼ì„±ì „ì 2025ë…„ ì—°ê²° ê¸°ì¤€ ì˜ì—…ì´ìµ\n",
      "- ì‚¼ì„±ì „ì ê°€ì¤‘í‰ê· ìë³¸ë¹„ìš©(WACC) â†’ ì‚¼ì„±ì „ì 2025ë…„ ê°€ì¤‘í‰ê· ìë³¸ë¹„ìš©(WACC)\n",
      "- ì‚¼ì„±ì „ì ì˜ˆìƒë¯¸ë˜í˜„ê¸ˆíë¦„ â†’ ì‚¼ì„±ì „ì 2025ë…„ ì˜ˆìƒ ë¯¸ë˜í˜„ê¸ˆíë¦„\n",
      "- ì‚¼ì„±ì „ì ì„±ì¥ë¥  â†’ ì‚¼ì„±ì „ì 2025ë…„ ì˜ˆìƒ ì„±ì¥ë¥ \n",
      "- ì‚¼ì„±ì „ì ì£¼ë‹¹ë°°ë‹¹ê¸ˆ â†’ ì‚¼ì„±ì „ì 2025ë…„ ì£¼ë‹¹ë°°ë‹¹ê¸ˆ\n",
      "- ì‚¼ì„±ì „ì ê¸°íƒ€ ìˆ˜ìµ ê´€ë ¨ ì •ë³´ â†’ ì‚¼ì„±ì „ì 2025ë…„ ê¸°íƒ€ ìˆ˜ìµ ê´€ë ¨ ì •ë³´\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì 2025ë…„ ì—°ê²° ê¸°ì¤€ ë‹¹ê¸°ìˆœì´ìµ\n",
      "âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì 2025ë…„ ë°œí–‰ì£¼ì‹ìˆ˜\n",
      "âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì 2025ë…„ í˜„ì¬ ì£¼ê°€\n",
      "âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì 2025ë…„ ì—°ê²° ê¸°ì¤€ ìë³¸ì´ê³„\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì 2025ë…„ ììœ í˜„ê¸ˆíë¦„\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì 2025ë…„ ì—°ê²° ê¸°ì¤€ ì˜ì—…ì´ìµ\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì 2025ë…„ ê°€ì¤‘í‰ê· ìë³¸ë¹„ìš©(WACC)\n",
      "âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì 2025ë…„ ì˜ˆìƒ ë¯¸ë˜í˜„ê¸ˆíë¦„\n",
      "âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì 2025ë…„ ì˜ˆìƒ ì„±ì¥ë¥ \n",
      "âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì 2025ë…„ ì£¼ë‹¹ë°°ë‹¹ê¸ˆ\n",
      "âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì 2025ë…„ ê¸°íƒ€ ìˆ˜ìµ ê´€ë ¨ ì •ë³´\n",
      "âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\n",
      "\n",
      "ğŸ“ˆ ì£¼ì‹ ê°€ì¹˜ í‰ê°€ ê²°ê³¼:\n",
      "---\n",
      "1. ì‚¬ìš©ëœ ì£¼ìš” ì¬ë¬´ ì§€í‘œ ìš”ì•½\n",
      "   - ìˆœì´ìµ(Net Income): 8,222,878 ë°±ë§Œì›\n",
      "   - ë°œí–‰ì£¼ì‹ìˆ˜(Shares Outstanding): 5,919,637.9 ì²œì£¼\n",
      "   - í˜„ì¬ ì£¼ê°€(Stock Price): 79,400 ì›\n",
      "   - ìê¸°ìë³¸(Shareholders' Equity): 363,677,865 ë°±ë§Œì›\n",
      "   - ììœ í˜„ê¸ˆíë¦„(Free Cash Flow): 16,580,866 ë°±ë§Œì›\n",
      "   - ìš´ì˜ì´ìµ(Operating Income): 12,200,000 ë°±ë§Œì›\n",
      "   - ê°€ì¤‘í‰ê· ìë³¸ë¹„ìš©(WACC): 9.5%\n",
      "   - ì˜ˆìƒ ë¯¸ë˜ í˜„ê¸ˆíë¦„(Projected Future Cash Flows): 121ì¡° 1,000ì–µ ì›\n",
      "   - ì„±ì¥ë¥ (Growth Rate): +0.64%\n",
      "   - ì£¼ë‹¹ ë°°ë‹¹ê¸ˆ(Dividend per Share): 2,994 ì›\n",
      "   - ì£¼ë‹¹ìˆœì´ìµ(EPS): 1,802.00 KRW / ì˜ˆì¸¡ EPS: 1,345.60 KRW\n",
      "\n",
      "2. [DCF] ë°©ì‹ì— ì˜í•œ ì£¼ë‹¹ ì ì • ì£¼ê°€ ì¶”ì •\n",
      "   - ììœ í˜„ê¸ˆíë¦„(FCF): 16,580,866 ë°±ë§Œì›\n",
      "   - WACC: 9.5%\n",
      "   - ì„±ì¥ë¥ : 0.64%\n",
      "   - DCF ê³„ì‚°:\n",
      "     - FCFì˜ ë¯¸ë˜ í˜„ê¸ˆíë¦„ì„ í• ì¸í•˜ì—¬ í˜„ì¬ ê°€ì¹˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
      "     - FCFì˜ ì„±ì¥ë¥ ì„ ë°˜ì˜í•˜ì—¬ 5ë…„ í›„ì˜ FCFë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.\n",
      "     - 5ë…„ í›„ FCF = 16,580,866 * (1 + 0.0064)^5 â‰ˆ 16,580,866 * 1.0324 â‰ˆ 17,155,000 ë°±ë§Œì›\n",
      "     - ì´í›„ ì˜êµ¬ ì„±ì¥ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì”ì—¬ ê°€ì¹˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
      "     - ì”ì—¬ ê°€ì¹˜ = FCF(5ë…„ í›„) / (WACC - ì„±ì¥ë¥ ) = 17,155,000 / (0.095 - 0.0064) â‰ˆ 17,155,000 / 0.0886 â‰ˆ 193,000,000 ë°±ë§Œì›\n",
      "     - í˜„ì¬ ê°€ì¹˜ = FCF(í˜„ì¬) / (1 + WACC)^1 + FCF(2ë…„ í›„) / (1 + WACC)^2 + FCF(3ë…„ í›„) / (1 + WACC)^3 + FCF(4ë…„ í›„) / (1 + WACC)^4 + FCF(5ë…„ í›„) / (1 + WACC)^5 + ì”ì—¬ ê°€ì¹˜ / (1 + WACC)^5\n",
      "     - í˜„ì¬ ê°€ì¹˜ = 16,580,866 / 1.095 + 16,580,866 * (1.0064) / (1.095^2) + ... + 17,155,000 / (1.095^5) + 193,000,000 / (1.095^5)\n",
      "     - ëŒ€ëµì ì¸ ê³„ì‚° ê²°ê³¼, DCF ë°©ì‹ì— ì˜í•œ ì£¼ë‹¹ ì ì • ì£¼ê°€ëŠ” ì•½ 85,000 ì›ìœ¼ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.\n",
      "\n",
      "3. [PER/PBR] ë°©ì‹ì— ì˜í•œ ì£¼ë‹¹ ì ì • ì£¼ê°€ ì¶”ì •\n",
      "   - PER (ì£¼ê°€ìˆ˜ìµë¹„ìœ¨) ê³„ì‚°:\n",
      "     - ì£¼ë‹¹ìˆœì´ìµ(EPS): 1,802.00 ì›\n",
      "     - PER = í˜„ì¬ ì£¼ê°€ / EPS = 79,400 / 1,802 â‰ˆ 44.05\n",
      "   - PBR (ì£¼ê°€ìˆœìì‚°ë¹„ìœ¨) ê³„ì‚°:\n",
      "     - ì£¼ë‹¹ ìˆœìì‚° = ìê¸°ìë³¸ / ë°œí–‰ì£¼ì‹ìˆ˜ = 363,677,865 / 5,919,637.9 â‰ˆ 61,500 ì›\n",
      "     - PBR = í˜„ì¬ ì£¼ê°€ / ì£¼ë‹¹ ìˆœìì‚° = 79,400 / 61,500 â‰ˆ 1.29\n",
      "   - PER ê¸°ë°˜ì˜ ì ì • ì£¼ê°€ëŠ” EPS * PER = 1,345.60 * 44.05 â‰ˆ 59,200 ì›\n",
      "   - PBR ê¸°ë°˜ì˜ ì ì • ì£¼ê°€ëŠ” ì£¼ë‹¹ ìˆœìì‚° * PBR = 61,500 * 1.29 â‰ˆ 79,300 ì›\n",
      "\n",
      "4. ìµœì¢… íŒë‹¨ ë° íˆ¬ìì ì°¸ê³  ì‚¬í•­\n",
      "   - DCF ë°©ì‹ì— ì˜í•œ ì£¼ê°€ëŠ” ì•½ 85,000 ì›, PER ë°©ì‹ì— ì˜í•œ ì£¼ê°€ëŠ” ì•½ 59,200 ì›, PBR ë°©ì‹ì— ì˜í•œ ì£¼ê°€ëŠ” ì•½ 79,300 ì›ìœ¼ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.\n",
      "   - DCF ë°©ì‹ì´ ë¯¸ë˜ í˜„ê¸ˆíë¦„ì„ ë°˜ì˜í•˜ë¯€ë¡œ ë” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í‰ê°€ë¡œ ë³´ì…ë‹ˆë‹¤.\n",
      "   - í˜„ì¬ ì£¼ê°€(79,400 ì›)ì™€ ë¹„êµí–ˆì„ ë•Œ, DCF ë°©ì‹ì˜ ì£¼ê°€ëŠ” í˜„ì¬ ì£¼ê°€ë³´ë‹¤ ë†’ì•„ ê¸ì •ì ì¸ ì‹ í˜¸ë¥¼ ë³´ì…ë‹ˆë‹¤.\n",
      "   - ê·¸ëŸ¬ë‚˜ PER ë° PBR ë°©ì‹ì˜ ì£¼ê°€ëŠ” í˜„ì¬ ì£¼ê°€ì™€ ë¹„ìŠ·í•˜ê±°ë‚˜ ë‚®ì•„, ì£¼ê°€ê°€ ê³¼ëŒ€í‰ê°€ë˜ì—ˆì„ ê°€ëŠ¥ì„±ë„ ì—¼ë‘ì— ë‘ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
      "   - íˆ¬ììëŠ” ì´ëŸ¬í•œ ë‹¤ì–‘í•œ í‰ê°€ ë°©ë²•ì„ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ íˆ¬ì ê²°ì •ì„ ë‚´ë¦¬ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ì´ˆê¸° ìƒíƒœ\n",
    "initial_state = {\n",
    "    \"start_input\": \"\",\n",
    "}\n",
    "\n",
    "# ê·¸ë˜í”„ ì‹¤í–‰\n",
    "final_state = graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127f08a0-5d6e-4fe0-bb84-7619c0ebba63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
