{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40772ae9-2d9b-4847-81f0-29ce83170850",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## states.py ########\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class OverallState(TypedDict):\n",
    "    user_input: str\n",
    "    messages: Annotated[list, add_messages]\n",
    "    character_persona_dict: dict\n",
    "\n",
    "class InputState(TypedDict):\n",
    "    start_input: str\n",
    "    \n",
    "class PersonaState(TypedDict):\n",
    "    user_input: str\n",
    "    messages: Annotated[list, add_messages]\n",
    "    character_persona_dict: dict\n",
    "    retrieve_check: bool\n",
    "    retrieval_msg: str\n",
    "    rewrite_query: str\n",
    "    tools_call_switch: Annotated[bool, True]\n",
    "\n",
    "class SearchQueryState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    character_persona_dict: dict\n",
    "    query_list: list\n",
    "    previous_query: list\n",
    "    is_revise: bool\n",
    "    \n",
    "class EndState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    query_list: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "464157e8-5bc7-43ad-a618-32937f97f207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbeace42-e9c0-4f99-8f4a-2fb8b8e07929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "주식분석\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"주식분석\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2bb9188-a479-4df3-af43-cd9124033560",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## nodes.py ########\n",
    "import os\n",
    "import json\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "# ChromaDB 로드\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding_function=OpenAIEmbeddings(),\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------\n",
    "# 시작노드 - 페르소나에 대한 정보를 요구하는 노드임\n",
    "def user_input_node(state: InputState):\n",
    "    print(\"================================= Make Persona =================================\")\n",
    "    print(\"페르소나를 결정합니다. 성별, 나이, 거주지, 취미 등 정보를 알려주세요.\")\n",
    "    # time.sleep(1)\n",
    "    user_input = input(\"User: \")\n",
    "    \n",
    "    return {\"messages\": [(\"user\", user_input)], \"tools_call_switch\": True}\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------\n",
    "# 노드 1 - 입력된 문장으로부터 새로운 페르소나를 만들어내는 노드.\n",
    "# 검색용 Tavily 툴 로드하고 노드만듦.\n",
    "tool = TavilySearchResults(max_results=3)\n",
    "web_search_tool = TavilySearchResults(max_results=5)\n",
    "\n",
    "# 노드 1-1. 검색용 노드\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "\n",
    "# 검색용 RAG 툴 로드하고 노드만듦\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retrieve_trends\",\n",
    "    \"Search for the latest trends in fashion and hobbies and return relevant information.\",\n",
    ")\n",
    "# 노드 1-2. RAG용 노드.\n",
    "retrieve = ToolNode([retriever_tool])\n",
    "\n",
    "def tool_nodes_exporter():\n",
    "    return tool_node, retrieve\n",
    "\n",
    "# 두 개 툴 엮어서 리스트 만듦.\n",
    "tools = [tool, retriever_tool]\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------\n",
    "# 노드 1-3. RAG 검증노드\n",
    "# 노드 1-2의 Tools Output을 받아서, User Input에 잘 맞는지 검증해서 Yes Or No로 대답함.\n",
    "# 만약 Yes라면 그대로 다시 Character Make Node로 보내서 최종 답변을 생성하도록 하고\n",
    "# 아니라면 검색을 진행하고 새로운 값을 받아서 보낼거임.\n",
    "\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "    binary_score:str = Field(..., description=\"Documents are relevant to the question, 'yes' or 'no'\", enum=['yes', 'no'])\n",
    "\n",
    "rag_check_model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "rag_check_model = rag_check_model.with_structured_output(GradeDocuments)\n",
    "\n",
    "def retrieve_check_node(state: PersonaState):\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"\"\"\n",
    "            You are a consultation expert who provides appropriate information in response to user input.\n",
    "            Return 'yes' or 'no' if you can provide an accurate answer to the user's question from the given documentation.\n",
    "            If you can't provide a clear answer, be sure to return NO.\n",
    "            \"\"\"),\n",
    "            (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User's input: {question}\"),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    retrieval_msg = state['messages'][-1].content\n",
    "    human_msg = state['user_input']\n",
    "    retrieval_grader = prompt | rag_check_model\n",
    "    response = retrieval_grader.invoke({\"document\": retrieval_msg, \"question\": human_msg})\n",
    "    retrieve_handle = response.binary_score\n",
    "    retrieve_check = False\n",
    "    \n",
    "    if retrieve_handle == \"no\":\n",
    "        print(\"=============================== Need to Check ===============================\")\n",
    "        retrieve_check = True\n",
    "    if retrieve_handle == \"yes\":\n",
    "        print(\"============================== No Need to Check =============================\")\n",
    "        \n",
    "    return {\"retrieve_check\": retrieve_check, \"retrieval_msg\": retrieval_msg}\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------\n",
    "# 노드 1-4. 쿼리 재-작성 노드\n",
    "# 노드 1-2에서 산출된 retrieve가 입력값과 적절하게 매치되지 않는 경우, 입력값을 수정하게 됨.\n",
    "# state User_input 이용\n",
    "# 이는 노드 1-3에서 yes를 반환하는 경우에 실행됨.\n",
    "\n",
    "class Rewrite_Output(TypedDict):\n",
    "    \"\"\"\n",
    "    Sturctured_output을 생성하기위한 클래스\n",
    "    \"\"\"\n",
    "    query: Annotated[str, ..., \"Rewritten query to find appropriate material on the web\"]\n",
    "\n",
    "rewrite_model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "rewrite_model = rewrite_model.with_structured_output(Rewrite_Output)\n",
    "\n",
    "def rewrite_node(state: PersonaState):\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"\"\"\n",
    "            You're an expert in improving search relevance.\\n\n",
    "            Look at previously entered search queries and rewrite them to better find that information on the internet.\n",
    "            \"\"\"),\n",
    "            (\"human\", \"Previously entered search queries: \\n{user_input}\"),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    user_input = state['user_input']\n",
    "    rewrite_chain = prompt | rewrite_model\n",
    "    response = rewrite_chain.invoke({\"user_input\": user_input})\n",
    "    rewrited_query = response['query']\n",
    "    print(f\"================================ Rewrited Query ================================\\nRewritted Query: {rewrited_query}\")\n",
    "\n",
    "    return {\"rewrite_query\": rewrited_query}\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------\n",
    "# 노드 1-5. 재작성된 쿼리를 이용해서 인터넷 검색하는 노드\n",
    "\n",
    "def rewrite_search_node(state: PersonaState):\n",
    "    print(\"================================ Search Web ================================\")\n",
    "    docs = web_search_tool.invoke({\"query\": state['rewrite_query']})\n",
    "    web_results = \"\\n\\n\".join([d[\"content\"] for d in docs])\n",
    "    web_results = web_results + \"\\n\\n\" + state['retrieval_msg']\n",
    "    # print(web_results)\n",
    "\n",
    "    new_messages = [ToolMessage(content=web_results, tool_call_id=\"tavily_search_results_json\")]\n",
    "            \n",
    "    return {\"messages\": new_messages}\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------\n",
    "# 노드 1번 작성된 것.\n",
    "# 인간 입력이랑 Retrieve를 받을 수 있는 놈임.\n",
    "\n",
    "character_model = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
    "character_model_with_tools = character_model.bind_tools(tools)\n",
    "\n",
    "def character_make_node(state: PersonaState):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\"\"\"\n",
    "        You are an expert in creating characters for fiction.\\n\n",
    "        Whatever input the user is presented with, you must return a description of the completed character.\\n\n",
    "        If no information is available, randomly generate and return the character's attributes.\\n\n",
    "        Based on the values entered by the user, envision and present the character, including the character's age, gender, job, location, interests, hobbies and etc.\\n\n",
    "        The returned value must be in Korean.\\n\n",
    "        \"\"\"),\n",
    "        (\"human\", \"Input: {human_input}\\n Retrieve: {context}\"),\n",
    "    ])\n",
    "    prompt_with_tools = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\"\"\"\n",
    "        You are an expert in creating characters for fiction.\\n\n",
    "        Whatever input the user is presented with, you must return a description of the completed character.\\n\n",
    "        If no information is available, randomly generate and return the character's attributes.\\n\n",
    "        Based on the values entered by the user, envision and present the character, including the character's age, gender, job, location, interests, hobbies and etc.\\n\n",
    "        If you have difficulty creating an appropriate character, use an online search to solve the problem.\\n\n",
    "        The returned value must be in Korean.\\n\n",
    "        \"\"\"),\n",
    "        (\"human\", \"Input: {human_input}\\n Retrieve: {context}\"),\n",
    "    ])\n",
    "    messages_list = state['messages']\n",
    "    last_human_message = next((msg for msg in reversed(messages_list) if isinstance(msg, HumanMessage)), None).content\n",
    "    last_msg = state['messages'][-1].content\n",
    "    \n",
    "    if last_human_message == last_msg:\n",
    "        last_msg = \"\"\n",
    "        print(f\"==================================== INPUT ====================================\\nHuman Input: {last_human_message}\")\n",
    "    else:\n",
    "        try:\n",
    "            last_msg_data = json.loads(state['messages'][-1].content)\n",
    "            last_msg = \"\\n\\n\".join([d[\"content\"] for d in last_msg_data])\n",
    "        except:\n",
    "            ...\n",
    "        print(f\"==================================== INPUT ====================================\\nHuman Input: {last_human_message}\\nContext: {last_msg}\")\n",
    "    \n",
    "    if state['tools_call_switch']:\n",
    "        chain_with_tools = prompt_with_tools | character_model_with_tools\n",
    "        response = chain_with_tools.invoke({\"human_input\": last_human_message, \"context\": last_msg})\n",
    "        \n",
    "        if hasattr(response, \"tool_calls\") and len(response.tool_calls) > 0 and (response.tool_calls[0][\"name\"]) == \"tavily_search_results_json\":\n",
    "            print(\"================================ Search Online ================================\")\n",
    "            tool_switch = False\n",
    "        elif hasattr(response, \"tool_calls\") and len(response.tool_calls) > 0 and (response.tool_calls[0][\"name\"]) == \"retrieve_trends\":\n",
    "            print(\"=============================== Search Retrieval ===============================\")\n",
    "            tool_switch = False\n",
    "        else:\n",
    "            print(\"============================= Chracter Information =============================\")\n",
    "            tool_switch = False\n",
    "            print(response.content)\n",
    "            \n",
    "    else:\n",
    "        chain = prompt | character_model\n",
    "        response = chain.invoke({\"human_input\": last_human_message, \"context\": last_msg})\n",
    "        print(\"============================= Chracter Information =============================\")\n",
    "        tool_switch = False\n",
    "        print(response.content)\n",
    "\n",
    "    return {\"messages\": [response], \"user_input\": last_human_message, \"tools_call_switch\": tool_switch}\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------\n",
    "# 노드2 - 입력된 문장으로부터 페르소나에 관한 정보를 추출하고, 정보가 없는 경우 이를 채워넣는 노드.\n",
    "class Persona_Output(TypedDict):\n",
    "    \"\"\"\n",
    "    Sturctured_output을 생성하기위한 클래스\n",
    "    \"\"\"\n",
    "    character_age: Annotated[str, ..., \"An age of the Persona\"]\n",
    "    character_sex: Annotated[str, ..., \"A sex of the Persona\"]\n",
    "    character_location: Annotated[str, ..., \"A place where the persona might live\"]\n",
    "    character_interest: Annotated[str, ..., \"Interests that the persona might have\"]\n",
    "    character_hobby: Annotated[str, ..., \"Hobbies that the persona might have\"]\n",
    "    character_job: Annotated[str, ..., \"Job that the persona might have\"]\n",
    "    character_information: Annotated[str, ..., \"Additional information to describe the persona\"]\n",
    "    \n",
    "persona_model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "persona_model = persona_model.with_structured_output(Persona_Output)\n",
    "\n",
    "# 페르소나를 반환하는 매우 경직된 LLM.\n",
    "# 정보가 없는 경우 임의의 값을 채워넣도록 되어있음.\n",
    "def persona_setup_node(state: PersonaState):\n",
    "    messages = [\n",
    "        (\"system\", \"\"\"\n",
    "         You are the expert in determining your character's persona.\n",
    "        Extract the character's 'age', 'sex', 'job', 'location', 'interest', and 'hobbies' from the values entered by the user.\n",
    "        If no information is available, it will return a randomised set of appropriate information that must be entered.\n",
    "        The returned value must be in Korean.\n",
    "        \"\"\"),\n",
    "        (\"human\", state['messages'][-1].content)\n",
    "    ]\n",
    "    response = persona_model.invoke(messages)\n",
    "    \n",
    "    print(\"================================= Persona Setup =================================\")\n",
    "    print(f\"성별: {response['character_sex']}\")\n",
    "    print(f\"나이: {response['character_age']}\")\n",
    "    print(f\"거주지: {response['character_location']}\")\n",
    "    print(f\"흥미: {response['character_interest']}\")\n",
    "    print(f\"취미: {response['character_hobby']}\")\n",
    "    print(f\"직업: {response['character_job']}\")\n",
    "    print(f\"추가정보: {response['character_information']}\")\n",
    "    \n",
    "    return {\"character_persona_dict\": response}\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------\n",
    "# 노드 3 - 페르소나를 토대로 적절한 검색 키워드를 생성하는 놈.\n",
    "\n",
    "class Search_Output(TypedDict):\n",
    "    \"\"\"\n",
    "    Sturctured_output을 생성하기위한 클래스\n",
    "    \"\"\"\n",
    "    query_list: Annotated[list, ..., \"List of queries that customers have entered in your shop\"]\n",
    "\n",
    "search_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "search_model = search_model.with_structured_output(Search_Output)\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \n",
    "        \"\"\"\n",
    "            User Sex: 여자,\n",
    "            User Age: 20대,\n",
    "            User Location: 서울 강남,\n",
    "            User Interest: 최신 화장법,\n",
    "            User Hobby: 공원 산책,\n",
    "            User Job: 그래픽 디자이너,\n",
    "            User Information: 강아지를 기르고 있음, 피부에 관심이 많음\n",
    "        \"\"\", \n",
    "    \"output\": \n",
    "        ['피부진정용 필링패드', '수분에센스', '스틱형 파운데이션', '강아지 간식', '강아지용 배변패드', '강아지 장난감']\n",
    "    },\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "def search_setence_node(state: SearchQueryState):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\"\"\"\n",
    "        You're a great marketing manager, and you're working on inferring customer search queries.\n",
    "        Given the customer information, generate appropriate search quries that customers might enter to find products in your shopping mall.\n",
    "        Make sure to clearly present the actual product names that a user with that persona would search for in your retail mall.\n",
    "        \"\"\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"\"\"\n",
    "         User Sex: {sex},\n",
    "         User Age: {age},\n",
    "         User Location: {location},\n",
    "         User Interest: {interest},\n",
    "         User Hobby: {hobby},\n",
    "         User Job: {job},\n",
    "         User Information: {information}\n",
    "         \"\"\"),\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | search_model\n",
    "    response = chain.invoke(\n",
    "        {\n",
    "            \"sex\": state['character_persona_dict']['character_sex'],\n",
    "            \"age\": state['character_persona_dict']['character_age'],\n",
    "            \"location\": state['character_persona_dict']['character_location'],\n",
    "            \"interest\": state['character_persona_dict']['character_interest'],\n",
    "            \"hobby\": state['character_persona_dict']['character_hobby'],\n",
    "            \"job\": state['character_persona_dict']['character_job'],\n",
    "            \"information\": state['character_persona_dict']['character_information'],\n",
    "        }\n",
    "    )\n",
    "    print(\"=============================== Search Queries ===============================\")\n",
    "    print(response['query_list'])\n",
    "    \n",
    "    return {\"query_list\": response}\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------\n",
    "# 노드 4, revise_tool - 반환된 서치쿼리가 적당한지 검증하는 노드임.\n",
    "class QueryReviseAssistance(BaseModel):\n",
    "    \"\"\"Escalate the conversation. \n",
    "    Use only if the given search query is a strong mismatch with the customer's information.\n",
    "    Use this tool even if given search query is seriously inappropriate to enter into the search bar of an online retailer like Amazon.\n",
    "    Never call the tool if the same input is still being given as before.\n",
    "    To use this function, return 'query_list'.\n",
    "    \"\"\"\n",
    "    query_list: list\n",
    "    \n",
    "query_check_model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5, streaming=True)\n",
    "query_check_model = query_check_model.bind_tools([QueryReviseAssistance])\n",
    "\n",
    "def query_check_node(state: SearchQueryState):\n",
    "    print(\"=============================== Query Check ===============================\")\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\"\"\"\n",
    "        You are a search manager.\n",
    "        If you think that the given customer's information and the search query that they used on your online store are relevant, then return the query as it is.\n",
    "        Never invoke the tool if you are still being given the same query that was entered in the previous dialogue.\n",
    "        \"\"\"),\n",
    "        (\"human\", \"\"\"\n",
    "            User Sex: {sex},\n",
    "            User Age: {age},\n",
    "            User Location: {location},\n",
    "            User Interest: {interest},\n",
    "            User Hobby: {hobby},\n",
    "            User Job: {job},\n",
    "            User Information: {information},\n",
    "            Queries: {queries}\n",
    "            \"\"\"),\n",
    "        ])\n",
    "    chain = prompt | query_check_model\n",
    "    \n",
    "    response = chain.invoke(\n",
    "        {\n",
    "            \"sex\": state['character_persona_dict']['character_sex'],\n",
    "            \"age\": state['character_persona_dict']['character_age'],\n",
    "            \"location\": state['character_persona_dict']['character_location'],\n",
    "            \"interest\": state['character_persona_dict']['character_interest'],\n",
    "            \"hobby\": state['character_persona_dict']['character_hobby'],\n",
    "            \"job\": state['character_persona_dict']['character_job'],\n",
    "            \"information\": state['character_persona_dict']['character_information'],\n",
    "            \"queries\": state['query_list']['query_list'],\n",
    "        }\n",
    "    )\n",
    "    is_revise = False\n",
    "        \n",
    "    if (\n",
    "        response.tool_calls\n",
    "        and response.tool_calls[0][\"name\"] == QueryReviseAssistance.__name__\n",
    "    ):\n",
    "        print(\"Revise Requires\")\n",
    "        is_revise = True\n",
    "    \n",
    "    return {\"messages\": [response], \"is_revise\": is_revise}\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------\n",
    "# 노드 4-1. 쿼리를 수정하도록 요청받은 경우 이를 수행하는 노드임.\n",
    "\n",
    "class QueryCheck_Output(TypedDict):\n",
    "    \"\"\"\n",
    "    Sturctured_output을 생성하기위한 클래스\n",
    "    \"\"\"\n",
    "    query_list: Annotated[list, ..., \"List of queries that customers might have entered in search-bar of your online retail shop\"]\n",
    "    \n",
    "query_revise_model = ChatOpenAI(model=\"gpt-4o\")\n",
    "query_revise_model = query_revise_model.with_structured_output(QueryCheck_Output)\n",
    "\n",
    "def query_revise_node(state: SearchQueryState):\n",
    "    print(\"=============================== Query Revise ===============================\")\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\n",
    "            \"\"\"\n",
    "                You are a validator who fixes errors in a given query.\n",
    "                From the list of queries given, remove or modify the queries that do not match the user's information appropriately.\n",
    "                Be sure to delete highly irrelevant data.\n",
    "                Be sure to remove search terms that you wouldn't use on a shopping site like Amazon.\n",
    "                Return the modified queries as a list.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\"human\", \n",
    "            \"\"\"\n",
    "                User Sex: {sex},\n",
    "                User Age: {age},\n",
    "                User Location: {location},\n",
    "                User Interest: {interest},\n",
    "                User Hobby: {hobby},\n",
    "                User Job: {job},\n",
    "                User Information: {information},\n",
    "                Queries: {queries}\n",
    "            \"\"\"\n",
    "        )])\n",
    "    \n",
    "    chain = prompt | query_revise_model\n",
    "    response = chain.invoke(\n",
    "        {\n",
    "            \"sex\": state['character_persona_dict']['character_sex'],\n",
    "            \"age\": state['character_persona_dict']['character_age'],\n",
    "            \"location\": state['character_persona_dict']['character_location'],\n",
    "            \"interest\": state['character_persona_dict']['character_interest'],\n",
    "            \"hobby\": state['character_persona_dict']['character_hobby'],\n",
    "            \"job\": state['character_persona_dict']['character_job'],\n",
    "            \"information\": state['character_persona_dict']['character_information'],\n",
    "            \"queries\": state['query_list']['query_list'],\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(response['query_list'])\n",
    "    \n",
    "    return {\"query_list\": response, \"is_revise\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fecd1af-fb58-4b53-a408-9b27c5c0ec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## edges.py ########\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# 라우팅을 위한 함수\n",
    "def select_next_node(state: SearchQueryState):\n",
    "    if state[\"is_revise\"]:\n",
    "        return \"is_revise\"\n",
    "    \n",
    "    return '__end__'\n",
    "\n",
    "def simple_route(state: PersonaState):\n",
    "    \"\"\"\n",
    "    Simplery Route Tools or Next or retrieve\n",
    "    \"\"\"\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0 and ai_message.tool_calls[0][\"name\"] == \"tavily_search_results_json\":\n",
    "        # print(\"Tavily Search Tool Call\")\n",
    "        return \"tools\"\n",
    "    elif hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0 and ai_message.tool_calls[0][\"name\"] == \"retrieve_trends\":\n",
    "        # print(\"Retrieve Call\")\n",
    "        return \"retrieve\"\n",
    "\n",
    "    return \"next\"\n",
    "\n",
    "def retrieve_route(state: PersonaState):\n",
    "    \"\"\"\n",
    "    RAG Need Check?\n",
    "    \"\"\"\n",
    "    if state['retrieve_check']:\n",
    "        return \"rewrite\"\n",
    "\n",
    "    return \"return\"\n",
    "\n",
    "tool_node, retrieve = tool_nodes_exporter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dd05f5e-aab9-4e7a-b48a-34297ca368d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x25ee91908c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 추가적인 필요사항 정리하고 그래프 빌딩\n",
    "memory = MemorySaver()\n",
    "graph_builder = StateGraph(OverallState, input=InputState, output=EndState)\n",
    "\n",
    "graph_builder.add_node(\"User Input\", user_input_node)\n",
    "graph_builder.add_node(\"Character Make\", character_make_node)\n",
    "graph_builder.add_node(\"Character Retrieve Check\", retrieve_check_node)\n",
    "graph_builder.add_node(\"Rewrite Tool\", rewrite_node)\n",
    "graph_builder.add_node(\"Rewrite-Search\", rewrite_search_node)\n",
    "graph_builder.add_node(\"Persona Setup\", persona_setup_node)\n",
    "graph_builder.add_node(\"Search Sentence\", search_setence_node)\n",
    "graph_builder.add_node(\"Query Check\", query_check_node)\n",
    "graph_builder.add_node(\"Query Revise Tool\", query_revise_node)\n",
    "graph_builder.add_node(\"Tavily Search Tool\", tool_node)\n",
    "graph_builder.add_node(\"RAG Tool\", retrieve)\n",
    "\n",
    "graph_builder.add_edge(START, \"User Input\")\n",
    "graph_builder.add_edge(\"User Input\", \"Character Make\")\n",
    "graph_builder.add_edge(\"Tavily Search Tool\", \"Character Make\")\n",
    "graph_builder.add_edge(\"RAG Tool\", \"Character Retrieve Check\")\n",
    "graph_builder.add_edge(\"Rewrite Tool\", \"Rewrite-Search\")\n",
    "graph_builder.add_edge(\"Rewrite-Search\", \"Character Make\")\n",
    "graph_builder.add_edge(\"Persona Setup\", \"Search Sentence\")\n",
    "graph_builder.add_edge(\"Search Sentence\", \"Query Check\")\n",
    "graph_builder.add_edge(\"Query Revise Tool\", \"Query Check\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"Query Check\", \n",
    "    select_next_node, \n",
    "    {\"is_revise\": \"Query Revise Tool\", END: END}\n",
    ")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"Character Make\",\n",
    "    simple_route,\n",
    "    {\"tools\": \"Tavily Search Tool\", \"next\": \"Persona Setup\", \"retrieve\": \"RAG Tool\"}\n",
    ")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"Character Retrieve Check\", \n",
    "    retrieve_route, \n",
    "    {\"rewrite\": \"Rewrite Tool\", \"return\": \"Character Make\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f5ccec7-ded7-417f-8d35-bbebba27c4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### edges.py에서 Graph Export #####\n",
    "def Project_Graph():\n",
    "    graph = graph_builder.compile(checkpointer=memory)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f5a093b-f747-4368-85df-45736e4e63fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to reach https://mermaid.ink/ API while trying to render your graph after 5 retries. To resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1427\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1428\u001b[0m     response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    721\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mTimeoutError\u001b[0m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    670\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    671\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    672\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    673\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    674\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    675\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    676\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    677\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    679\u001b[0m     )\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m retries\u001b[38;5;241m.\u001b[39mincrement(\n\u001b[0;32m    844\u001b[0m     method, url, error\u001b[38;5;241m=\u001b[39mnew_e, _pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _stacktrace\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    845\u001b[0m )\n\u001b[0;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py:474\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[1;32m--> 474\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m reraise(\u001b[38;5;28mtype\u001b[39m(error), error, _stacktrace)\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\util.py:39\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    790\u001b[0m     conn,\n\u001b[0;32m    791\u001b[0m     method,\n\u001b[0;32m    792\u001b[0m     url,\n\u001b[0;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    802\u001b[0m )\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:538\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:369\u001b[0m, in \u001b[0;36mHTTPConnectionPool._raise_timeout\u001b[1;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[1;32m--> 369\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[0;32m    370\u001b[0m         \u001b[38;5;28mself\u001b[39m, url, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    371\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3.\u001b[39;00m\n",
      "\u001b[1;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='mermaid.ink', port=443): Read timed out. (read timeout=10)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:430\u001b[0m, in \u001b[0;36m_render_mermaid_using_api\u001b[1;34m(mermaid_syntax, output_file_path, background_color, file_type, max_retries, retry_delay)\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 430\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(image_url, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m requests\u001b[38;5;241m.\u001b[39mcodes\u001b[38;5;241m.\u001b[39mok:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:713\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[1;32m--> 713\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    714\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _InvalidHeader):\n",
      "\u001b[1;31mReadTimeout\u001b[0m: HTTPSConnectionPool(host='mermaid.ink', port=443): Read timed out. (read timeout=10)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m config \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthread_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m}}\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraph_output_ori.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      7\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\n\u001b[1;32m----> 8\u001b[0m         graph\u001b[38;5;241m.\u001b[39mget_graph()\u001b[38;5;241m.\u001b[39mdraw_mermaid_png(\n\u001b[0;32m      9\u001b[0m             max_retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m     10\u001b[0m             retry_delay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.0\u001b[39m\n\u001b[0;32m     11\u001b[0m         )\n\u001b[0;32m     12\u001b[0m     )\n\u001b[0;32m     14\u001b[0m graph\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_input\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m}, config\u001b[38;5;241m=\u001b[39mconfig)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\graph.py:685\u001b[0m, in \u001b[0;36mGraph.draw_mermaid_png\u001b[1;34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding, max_retries, retry_delay, frontmatter_config)\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_mermaid\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m draw_mermaid_png\n\u001b[0;32m    679\u001b[0m mermaid_syntax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_mermaid(\n\u001b[0;32m    680\u001b[0m     curve_style\u001b[38;5;241m=\u001b[39mcurve_style,\n\u001b[0;32m    681\u001b[0m     node_colors\u001b[38;5;241m=\u001b[39mnode_colors,\n\u001b[0;32m    682\u001b[0m     wrap_label_n_words\u001b[38;5;241m=\u001b[39mwrap_label_n_words,\n\u001b[0;32m    683\u001b[0m     frontmatter_config\u001b[38;5;241m=\u001b[39mfrontmatter_config,\n\u001b[0;32m    684\u001b[0m )\n\u001b[1;32m--> 685\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m draw_mermaid_png(\n\u001b[0;32m    686\u001b[0m     mermaid_syntax\u001b[38;5;241m=\u001b[39mmermaid_syntax,\n\u001b[0;32m    687\u001b[0m     output_file_path\u001b[38;5;241m=\u001b[39moutput_file_path,\n\u001b[0;32m    688\u001b[0m     draw_method\u001b[38;5;241m=\u001b[39mdraw_method,\n\u001b[0;32m    689\u001b[0m     background_color\u001b[38;5;241m=\u001b[39mbackground_color,\n\u001b[0;32m    690\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m    691\u001b[0m     max_retries\u001b[38;5;241m=\u001b[39mmax_retries,\n\u001b[0;32m    692\u001b[0m     retry_delay\u001b[38;5;241m=\u001b[39mretry_delay,\n\u001b[0;32m    693\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:293\u001b[0m, in \u001b[0;36mdraw_mermaid_png\u001b[1;34m(mermaid_syntax, output_file_path, draw_method, background_color, padding, max_retries, retry_delay)\u001b[0m\n\u001b[0;32m    287\u001b[0m     img_bytes \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m    288\u001b[0m         _render_mermaid_using_pyppeteer(\n\u001b[0;32m    289\u001b[0m             mermaid_syntax, output_file_path, background_color, padding\n\u001b[0;32m    290\u001b[0m         )\n\u001b[0;32m    291\u001b[0m     )\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m draw_method \u001b[38;5;241m==\u001b[39m MermaidDrawMethod\u001b[38;5;241m.\u001b[39mAPI:\n\u001b[1;32m--> 293\u001b[0m     img_bytes \u001b[38;5;241m=\u001b[39m _render_mermaid_using_api(\n\u001b[0;32m    294\u001b[0m         mermaid_syntax,\n\u001b[0;32m    295\u001b[0m         output_file_path\u001b[38;5;241m=\u001b[39moutput_file_path,\n\u001b[0;32m    296\u001b[0m         background_color\u001b[38;5;241m=\u001b[39mbackground_color,\n\u001b[0;32m    297\u001b[0m         max_retries\u001b[38;5;241m=\u001b[39mmax_retries,\n\u001b[0;32m    298\u001b[0m         retry_delay\u001b[38;5;241m=\u001b[39mretry_delay,\n\u001b[0;32m    299\u001b[0m     )\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    301\u001b[0m     supported_methods \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([m\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m MermaidDrawMethod])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:462\u001b[0m, in \u001b[0;36m_render_mermaid_using_api\u001b[1;34m(mermaid_syntax, output_file_path, background_color, file_type, max_retries, retry_delay)\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    459\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reach https://mermaid.ink/ API while trying to render \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    460\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour graph after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m retries. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    461\u001b[0m             ) \u001b[38;5;241m+\u001b[39m error_msg_suffix\n\u001b[1;32m--> 462\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;66;03m# This should not be reached, but just in case\u001b[39;00m\n\u001b[0;32m    465\u001b[0m msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reach https://mermaid.ink/ API while trying to render \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour graph after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m retries. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    468\u001b[0m ) \u001b[38;5;241m+\u001b[39m error_msg_suffix\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to reach https://mermaid.ink/ API while trying to render your graph after 5 retries. To resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`"
     ]
    }
   ],
   "source": [
    "####### run_graph.py #######\n",
    "\n",
    "graph = Project_Graph()\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "with open(\"graph_output_ori.png\", \"wb\") as f:\n",
    "    f.write(\n",
    "        graph.get_graph().draw_mermaid_png(\n",
    "            max_retries=5,\n",
    "            retry_delay=2.0\n",
    "        )\n",
    "    )\n",
    "    \n",
    "graph.invoke({\"start_input\": \"\"}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95399931-8f4f-4dc1-bcec-8d4ef792fdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyppeteer\n",
      "  Downloading pyppeteer-2.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in c:\\users\\minhy\\anaconda3\\lib\\site-packages (from pyppeteer) (1.4.4)\n",
      "Requirement already satisfied: certifi>=2023 in c:\\users\\minhy\\anaconda3\\lib\\site-packages (from pyppeteer) (2024.8.30)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in c:\\users\\minhy\\anaconda3\\lib\\site-packages (from pyppeteer) (7.0.1)\n",
      "Collecting pyee<12.0.0,>=11.0.0 (from pyppeteer)\n",
      "  Downloading pyee-11.1.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in c:\\users\\minhy\\anaconda3\\lib\\site-packages (from pyppeteer) (4.66.5)\n",
      "Collecting urllib3<2.0.0,>=1.25.8 (from pyppeteer)\n",
      "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
      "Collecting websockets<11.0,>=10.0 (from pyppeteer)\n",
      "  Downloading websockets-10.4.tar.gz (84 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\minhy\\anaconda3\\lib\\site-packages (from importlib-metadata>=1.4->pyppeteer) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\minhy\\anaconda3\\lib\\site-packages (from pyee<12.0.0,>=11.0.0->pyppeteer) (4.13.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\minhy\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.42.1->pyppeteer) (0.4.6)\n",
      "Downloading pyppeteer-2.0.0-py3-none-any.whl (82 kB)\n",
      "Downloading pyee-11.1.1-py3-none-any.whl (15 kB)\n",
      "Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "Building wheels for collected packages: websockets\n",
      "  Building wheel for websockets (setup.py): started\n",
      "  Building wheel for websockets (setup.py): finished with status 'done'\n",
      "  Created wheel for websockets: filename=websockets-10.4-cp312-cp312-win_amd64.whl size=100940 sha256=f890f31796aba0145ffda3dbcb9702a222b2e01cb55ac5b95a915b70b757a732\n",
      "  Stored in directory: c:\\users\\minhy\\appdata\\local\\pip\\cache\\wheels\\80\\cf\\6d\\5d7e4c920cb41925a178b2d2621889c520d648bab487b1d7fd\n",
      "Successfully built websockets\n",
      "Installing collected packages: websockets, urllib3, pyee, pyppeteer\n",
      "  Attempting uninstall: websockets\n",
      "    Found existing installation: websockets 15.0.1\n",
      "    Uninstalling websockets-15.0.1:\n",
      "      Successfully uninstalled websockets-15.0.1\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.3\n",
      "    Uninstalling urllib3-2.2.3:\n",
      "      Successfully uninstalled urllib3-2.2.3\n",
      "Successfully installed pyee-11.1.1 pyppeteer-2.0.0 urllib3-1.26.20 websockets-10.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.114 requires urllib3>=2.2.2, but you have urllib3 1.26.20 which is incompatible.\n",
      "types-requests 2.32.0.20250328 requires urllib3>=2, but you have urllib3 1.26.20 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install pyppeteer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb15b74-ca9e-4d3a-8634-4057e68aa388",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
