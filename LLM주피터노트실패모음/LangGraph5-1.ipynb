{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66aeb681-0452-4b25-a9fd-e24a5ed844d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY ì •ë³´ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6603e3ad-26d9-4388-8553-42d9946855e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "ì£¼ì‹ë¶„ì„\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "logging.langsmith(\"ì£¼ì‹ë¶„ì„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa766e47-1da0-4d73-bd79-86ef18cb17cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Annotated, List, Dict\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.messages import HumanMessage, ToolMessage, AIMessage\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.tools.retriever import create_retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "053180a3-c4cf-4e3c-a1df-9c9dea6a0184",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## states ì •ì˜ ########\n",
    "class InputState(TypedDict):\n",
    "    start_input: str\n",
    "\n",
    "class OverallState(TypedDict):\n",
    "    user_input: str\n",
    "    messages: Annotated[list, add_messages]\n",
    "    Stock_Value_dict: dict\n",
    "    query_list: List[str]\n",
    "\n",
    "class EndState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    query_list: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5299c4dd-a103-4a39-af77-78f9f74fdd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ìš©ì ì…ë ¥ ë…¸ë“œ ì •ì˜\n",
    "def user_input_node(state: InputState):\n",
    "    print(\"================================= calculation stock =================================\")\n",
    "    print(\"ì£¼ì‹ ê°€ì¹˜ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. ê¶ê¸ˆí•˜ì‹  ì£¼ì‹ëª…ì„ ë§ì”€í•´ì£¼ì„¸ìš”.\")\n",
    "    user_input = input(\"User: \")\n",
    "\n",
    "    return {\n",
    "        \"user_input\": user_input,\n",
    "        \"messages\": [(\"user\", user_input)],\n",
    "        \"Stock_Value_dict\": {},  # ë‚˜ì¤‘ì— ì—¬ê¸°ì— ë°ì´í„° ì±„ì›Œì§\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09d5d5a5-69a0-4ded-8007-1a5b15803893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_query_generation_node(state: OverallState):\n",
    "    user_input = state[\"user_input\"]\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ê¸ˆìœµ ì •ë³´ë¥¼ ì°¾ê¸° ìœ„í•œ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\"),\n",
    "        (\"human\", '''\n",
    "ì‚¬ìš©ì ì…ë ¥: \"{user_input}\"ì„ ì°¸ê³ í•˜ì—¬ ì•„ë˜ ë‚´ìš©ì— ëŒ€í•´ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.\n",
    "  \"ë‹¹ê¸°ìˆœì´ìµ\",\n",
    "  \"ë°œí–‰ì£¼ì‹ìˆ˜\",\n",
    "  \"í˜„ì¬ ì£¼ê°€\",\n",
    "  \"ìë³¸ì´ê³„\",\n",
    "  \"ììœ í˜„ê¸ˆíë¦„\",\n",
    "  \"ì˜ì—…ì´ìµ\",\n",
    "  \"ê°€ì¤‘í‰ê· ìë³¸ë¹„ìš©(WACC)\",\n",
    "  \"ì˜ˆìƒë¯¸ë˜í˜„ê¸ˆíë¦„\",\n",
    "  \"ì„±ì¥ë¥ \",\n",
    "  \"ì£¼ë‹¹ë°°ë‹¹ê¸ˆ\",\n",
    "  \"ê¸°íƒ€ ìˆ˜ìµ ê´€ë ¨ ì •ë³´\"\n",
    "ì¶œë ¥ í˜•ì‹ì€ ë°˜ë“œì‹œ JSON ë°°ì—´ì…ë‹ˆë‹¤. \n",
    "''')\n",
    "    ])\n",
    "\n",
    "    messages = prompt.format_messages(user_input=user_input)\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    try:\n",
    "        cleaned = re.sub(r\"^```(?:json)?\\n|\\n```$\", \"\", response.content.strip())\n",
    "        query_list = json.loads(cleaned)\n",
    "    except Exception as e:\n",
    "        print(f\"â— ê²€ìƒ‰ ì¿¼ë¦¬ íŒŒì‹± ì‹¤íŒ¨: {e}\")\n",
    "        query_list = []\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"query_list\": query_list\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d91186b6-f6a4-4b8f-977e-bfdd3ec9fb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_refine_node(state: OverallState) -> OverallState:\n",
    "    original_queries = state.get(\"query_list\", [])\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "\n",
    "    # ğŸ”¹ few-shot ì˜ˆì‹œ\n",
    "    examples = [\n",
    "        {\n",
    "            \"input\": [\"ì‚¼ì„±ì „ì ë‹¹ê¸°ìˆœì´ìµ\", \"ì‚¼ì„±ì „ì ë°œí–‰ì£¼ì‹ìˆ˜\"],\n",
    "            \"output\": [\"ì‚¼ì„±ì „ì 2025ë…„ ì—°ê²° ê¸°ì¤€ ë‹¹ê¸°ìˆœì´ìµ\", \"ì‚¼ì„±ì „ì 2025ë…„ ë°œí–‰ì£¼ì‹ìˆ˜\"]\n",
    "        },\n",
    "        {\n",
    "            \"input\": [\"LGì—ë„ˆì§€ì†”ë£¨ì…˜ ì˜ì—…ì´ìµ\", \"LGì—ë„ˆì§€ì†”ë£¨ì…˜ ì„±ì¥ë¥ \"],\n",
    "            \"output\": [\"LGì—ë„ˆì§€ì†”ë£¨ì…˜ 2025ë…„ ì—°ê²° ê¸°ì¤€ ì˜ì—…ì´ìµ\", \"LGì—ë„ˆì§€ì†”ë£¨ì…˜ 2025ë…„ ì˜ˆìƒ ì„±ì¥ë¥ \"]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    few_shot_format = \"\\n\\n\".join([\n",
    "        f\"ì…ë ¥: {ex['input']}\\në³´ì • ê²°ê³¼: {ex['output']}\"\n",
    "        for ex in examples\n",
    "    ])\n",
    "\n",
    "    refine_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", f\"\"\"\n",
    "ë‹¹ì‹ ì€ ì „ìê³µì‹œì‹œìŠ¤í…œ(DART) ë¬¸ì„œì— ì í•©í•œ ê²€ìƒ‰ì–´ë¥¼ ë³´ì •í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ìŒ ì›ë³¸ ê²€ìƒ‰ì–´ ëª©ë¡ì„ ì°¸ê³ í•˜ì—¬ DART ë¬¸ì„œì—ì„œ ì‹¤ì œë¡œ ê²€ìƒ‰ì´ ì˜ ë˜ë„ë¡ ì¿¼ë¦¬ë¥¼ ë³´ì •í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "### ë³´ì • ê·œì¹™:\n",
    "- ì—°ê²°/ê°œë³„ ê¸°ì¤€ì´ ìˆë‹¤ë©´ ê·¸ëŒ€ë¡œ ìœ ì§€\n",
    "- 2025ë…„ ê°™ì€ ì—°ë„ ì •ë³´ëŠ” **ë¶™ì´ì§€ ë§ˆì„¸ìš”**\n",
    "- \"í˜„ê¸ˆíë¦„\" â†’ \"í˜„ê¸ˆíë¦„í‘œ\", \"ë°°ë‹¹ê¸ˆ\" â†’ \"ë°°ë‹¹ê¸ˆ ì§€ê¸‰ ê³„íš\" ë“± ë³´ê³ ì„œ ìš©ì–´ì— ë§ê²Œ ê³ ì¹˜ì„¸ìš”\n",
    "- ë³´ì •ëœ ì¿¼ë¦¬ëŠ” ë¬¸ì„œì—ì„œ ë°”ë¡œ ê²€ìƒ‰ì´ ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì¶œë ¥ í˜•ì‹ì€ ë°˜ë“œì‹œ JSON ë°°ì—´ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤:\n",
    "{few_shot_format}\n",
    "\"\"\"),\n",
    "        (\"human\", \"\"\"\n",
    "ì›ë³¸ ì¿¼ë¦¬ ëª©ë¡:\n",
    "{query_list}\n",
    "\"\"\")\n",
    "    ])\n",
    "\n",
    "    messages = refine_prompt.format_messages(query_list=json.dumps(original_queries, ensure_ascii=False))\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    try:\n",
    "        cleaned = re.sub(r\"^```(?:json)?\\n|\\n```$\", \"\", response.content.strip())\n",
    "        refined_queries = json.loads(cleaned)\n",
    "    except Exception as e:\n",
    "        print(f\"â— ì¿¼ë¦¬ ë³´ì • ì‹¤íŒ¨: {e}\")\n",
    "        refined_queries = original_queries\n",
    "\n",
    "    print(\"\\nğŸ” ì¿¼ë¦¬ ë³´ì • ê²°ê³¼:\")\n",
    "    for o, r in zip(original_queries, refined_queries):\n",
    "        print(f\"- {o} â†’ {r}\")\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"query_list\": refined_queries,\n",
    "        \"previous_query\": original_queries,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6ad462f-65ed-48f6-8f53-833584a16a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë³¸ ë¬¸ì„œ ìˆ˜: 404\n",
      "ì¤‘ë³µ ì œê±° í›„ ë¬¸ì„œ ìˆ˜: 403\n"
     ]
    }
   ],
   "source": [
    "######## nodes.py ########\n",
    "# --- ë¬¸ì„œ ë¡œë“œ ë° ì „ì²˜ë¦¬ ---\n",
    "loader = PyMuPDFLoader(\"stock_report/[ì‚¼ì„±ì „ì]ë¶„ê¸°ë³´ê³ ì„œ(2024.11.14).pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "## : ë¬¸ì„œ ë¶„í• (Split Documents) <-----------ì¶”í›„ ë¬¸ì„œ ì œëª© ë‹¨ìœ„ ë¶„í• ë¡œ ë³€ê²½ í•„ìš”\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=500)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# ì¤‘ë³µ ì œê±°\n",
    "unique_documents = []\n",
    "seen_contents = set()\n",
    "\n",
    "for doc in split_documents:\n",
    "    content = doc.page_content.strip()\n",
    "    if content not in seen_contents:\n",
    "        seen_contents.add(content)\n",
    "        unique_documents.append(doc)\n",
    "\n",
    "print(f\"ì›ë³¸ ë¬¸ì„œ ìˆ˜: {len(split_documents)}\")\n",
    "print(f\"ì¤‘ë³µ ì œê±° í›„ ë¬¸ì„œ ìˆ˜: {len(unique_documents)}\")\n",
    "\n",
    "## ë‹¨ê³„ 3: ì„ë² ë”©(Embedding) ìƒì„±\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# ë²¡í„°ìŠ¤í† ì–´ ìƒì„±\n",
    "vectorstore = Chroma.from_documents(documents=split_documents, embedding=embeddings, persist_directory=\"stock_report/chroma_db\")\n",
    "\n",
    "# 5. ê²€ìƒ‰ê¸°(Retriever) ìƒì„±\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20eb4170-a4d2-48ab-9769-59ad14c08fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_mapping = {\n",
    "    \"ë‹¹ê¸°ìˆœì´ìµ\": \"Net_Income\",\n",
    "    \"ë°œí–‰ì£¼ì‹ìˆ˜\": \"Shares_Outstanding\",\n",
    "    \"í˜„ì¬ ì£¼ê°€\": \"Stock_Price\",\n",
    "    \"ìë³¸ì´ê³„\": \"Shareholders_equity\",\n",
    "    \"ììœ í˜„ê¸ˆíë¦„\": \"Free_cash_flow\",\n",
    "    \"ì˜ì—…ì´ìµ\": \"Operating_income\",\n",
    "    \"ê°€ì¤‘í‰ê· ìë³¸ë¹„ìš©\": \"WACC\",\n",
    "    \"ì˜ˆìƒë¯¸ë˜í˜„ê¸ˆíë¦„\": \"Projected_future_cash_flows\",\n",
    "    \"ì„±ì¥ë¥ \": \"Growth_Rate\",\n",
    "    \"ì£¼ë‹¹ë°°ë‹¹ê¸ˆ\": \"Dividend_per_share\",\n",
    "    \"ê¸°íƒ€ ìˆ˜ìµ ê´€ë ¨ ì •ë³´\": \"Other_return_related_information\",\n",
    "}\n",
    "\n",
    "summary_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "ë‹¹ì‹ ì€ ê¸°ì—…ì˜ ì¬ë¬´ ì •ë³´ë¥¼ ìš”ì•½í•˜ëŠ” ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "ë‹¤ìŒ ë¬¸ì„œë¥¼ ì½ê³ , ì•„ë˜ í•­ëª©ì— ëŒ€í•´ **ì •í™•í•œ ê°’ê³¼ ë‹¨ìœ„**ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.\n",
    "\n",
    "ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš” (JSON):\n",
    "{{\n",
    "  \"ë‹¹ê¸°ìˆœì´ìµ\": \"...\",\n",
    "  \"ë°œí–‰ì£¼ì‹ìˆ˜\": \"...\",\n",
    "  \"í˜„ì¬ ì£¼ê°€\": \"...\",\n",
    "  \"ìë³¸ì´ê³„\": \"...\",\n",
    "  \"ììœ í˜„ê¸ˆíë¦„\": \"...\",\n",
    "  \"ì˜ì—…ì´ìµ\": \"...\",\n",
    "  \"ê°€ì¤‘í‰ê· ìë³¸ë¹„ìš©(WACC)\": \"...\",\n",
    "  \"ì˜ˆìƒë¯¸ë˜í˜„ê¸ˆíë¦„\": \"...\",\n",
    "  \"ì„±ì¥ë¥ \": \"...\",\n",
    "  \"ì£¼ë‹¹ë°°ë‹¹ê¸ˆ\": \"...\",\n",
    "  \"ê¸°íƒ€ ìˆ˜ìµ ê´€ë ¨ ì •ë³´\": \"...\"\n",
    "}}\n",
    "\n",
    "ê°’ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë¬¸ì„œì— ëª…í™•íˆ ì—†ìœ¼ë©´ \"ì—†ìŒ\"ì´ë¼ê³  í‘œê¸°í•˜ì„¸ìš”.\n",
    "\"\"\"),\n",
    "    (\"human\", \"{context}\")\n",
    "])\n",
    "\n",
    "def summarize_context(context: str, llm) -> dict:\n",
    "    messages = summary_prompt.format_messages(context=context)\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    try:\n",
    "        raw = re.sub(r\"^```(?:json)?\\n|\\n```$\", \"\", response.content.strip())\n",
    "        parsed = json.loads(raw)\n",
    "        return {key_mapping.get(k, k): v for k, v in parsed.items()}\n",
    "    except Exception as e:\n",
    "        print(f\"â— ìš”ì•½ íŒŒì‹± ì‹¤íŒ¨: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dd20d91-7758-4168-8e82-072ca9eeb76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(parsed: dict, stock_data: dict):\n",
    "    for k, v in parsed.items():\n",
    "        if k not in stock_data or stock_data[k] == \"ì—†ìŒ\":\n",
    "            stock_data[k] = v\n",
    "\n",
    "def query_loop_node(state: OverallState) -> OverallState:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    tavily = TavilySearchResults(max_results=3)\n",
    "\n",
    "    stock_data = {}\n",
    "    fallback_queries = []\n",
    "    key_fields_to_check = [\"Net_Income\", \"Operating_income\", \"Free_cash_flow\"]\n",
    "\n",
    "    for query in state[\"query_list\"]:\n",
    "        print(f\"\\nğŸ” [RAG ê²€ìƒ‰] {query}\")\n",
    "\n",
    "        try:\n",
    "            docs = list({doc.page_content.strip() for doc in retriever.invoke(query)})\n",
    "            context = \"\\n\\n\".join(docs)[:3000]\n",
    "        except Exception as e:\n",
    "            print(f\"â— RAG ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            context = \"\"\n",
    "\n",
    "        parsed = summarize_context(context, llm)\n",
    "\n",
    "        if all(parsed.get(k, \"ì—†ìŒ\") == \"ì—†ìŒ\" for k in key_fields_to_check):\n",
    "            print(\"âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\")\n",
    "            fallback_queries.append(query)\n",
    "\n",
    "            try:\n",
    "                web_result = tavily.invoke({\"query\": query})\n",
    "\n",
    "                # âœ… ì›¹ ê²°ê³¼ê°€ listì¸ì§€ í™•ì¸\n",
    "                if isinstance(web_result, list):\n",
    "                    web_context = \"\\n\\n\".join([doc.get(\"content\", \"\") for doc in web_result])[:3000]\n",
    "                else:\n",
    "                    web_context = \"\\n\\n\".join([doc.get(\"content\", \"\") for doc in web_result.get(\"documents\", [])])[:3000]\n",
    "\n",
    "                if web_context.strip():\n",
    "                    parsed = summarize_context(web_context, llm)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"â— ì›¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "        # regardless of source (RAG or web), merge\n",
    "        merge(parsed, stock_data)\n",
    "\n",
    "    # ëˆ„ë½ëœ í•­ëª© \"ì—†ìŒ\" ì±„ìš°ê¸°\n",
    "    for key in key_mapping.values():\n",
    "        if key not in stock_data:\n",
    "            stock_data[key] = \"ì—†ìŒ\"\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"Stock_Value_dict\": stock_data,\n",
    "        \"fallback_queries\": fallback_queries,\n",
    "        \"messages\": state[\"messages\"] + [AIMessage(content=\"âœ… í•µì‹¬ í‚¤ ê¸°ì¤€ RAG + ì›¹ fallback ì™„ë£Œ\")],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2600323d-7771-450b-8667-8d92b8213bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_fallback_node(state: OverallState) -> OverallState:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    web = TavilySearchResults(max_results=3)\n",
    "    stock_data = state[\"Stock_Value_dict\"]\n",
    "    fallback_queries = state.get(\"fallback_queries\", [])\n",
    "\n",
    "    for query in fallback_queries:\n",
    "        print(f\"ğŸŒ [ì›¹ ê²€ìƒ‰ fallback] {query}\")\n",
    "        web_result = web.invoke({\"query\": query})\n",
    "        web_context = \"\\n\\n\".join([d[\"content\"] for d in web_result[\"documents\"]])[:3000]\n",
    "        parsed = summarize_context(web_context, llm)\n",
    "        merge(parsed, stock_data)\n",
    "\n",
    "    return {\n",
    "        \"Stock_Value_dict\": stock_data,\n",
    "        \"messages\": state[\"messages\"] + [AIMessage(content=\"ğŸŒ ì›¹ ê²€ìƒ‰ ë³´ì™„ ì™„ë£Œ\")],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ef906d5-a030-4cb8-a7dc-fee97ae0c514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_valuation_node(state: OverallState) -> OverallState:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    financials = state.get(\"Stock_Value_dict\", {})\n",
    "    user_input = state.get(\"user_input\", \"\")\n",
    "\n",
    "    valuation_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"\n",
    "ë‹¹ì‹ ì€ ê¸°ì—…ì˜ ì¬ë¬´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°€ì¹˜ë¥¼ í‰ê°€í•˜ëŠ” ê¸ˆìœµ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ìŒ ì¬ë¬´ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **ì‚¼ì„±ì „ìì˜ ì£¼ì‹ ê°€ì¹˜ë¥¼ ì¶”ì •**í•´ ì£¼ì„¸ìš”.\n",
    "- ê°€ëŠ¥í•˜ë©´ **ììœ í˜„ê¸ˆíë¦„ í• ì¸ë²•(DCF)** ëª¨ë¸ì„ ì‚¬ìš©í•˜ê³ , \n",
    "- **PER/PBR** ê¸°ë°˜ì˜ ë³´ì™„ì  ê³„ì‚°ë„ í•¨ê»˜ ì§„í–‰í•´ ì£¼ì„¸ìš”.\n",
    "\n",
    "ì¶œë ¥ì€ ë‹¤ìŒ í˜•ì‹ì„ ë”°ë¦…ë‹ˆë‹¤:\n",
    "\n",
    "---\n",
    "1. ì‚¬ìš©ëœ ì£¼ìš” ì¬ë¬´ ì§€í‘œ ìš”ì•½\n",
    "2. [DCF] ë°©ì‹ì— ì˜í•œ ì£¼ë‹¹ ì ì • ì£¼ê°€ ì¶”ì •\n",
    "3. [PER/PBR] ë°©ì‹ì— ì˜í•œ ì£¼ë‹¹ ì ì • ì£¼ê°€ ì¶”ì •\n",
    "4. ìµœì¢… íŒë‹¨ ë° íˆ¬ìì ì°¸ê³  ì‚¬í•­\n",
    "\n",
    "ë°ì´í„°:\n",
    "{financials}\n",
    "\"\"\"),\n",
    "        (\"human\", f\"{user_input}ì˜ ì£¼ì‹ ê°€ì¹˜ë¥¼ í‰ê°€í•´ì¤˜.\")\n",
    "    ])\n",
    "\n",
    "    messages = valuation_prompt.format_messages(financials=json.dumps(financials, ensure_ascii=False))\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    print(\"\\nğŸ“ˆ ì£¼ì‹ ê°€ì¹˜ í‰ê°€ ê²°ê³¼:\")\n",
    "    print(response.content.strip())\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"valuation_result\": response.content.strip(),\n",
    "        \"messages\": state[\"messages\"] + [AIMessage(content=\"ğŸ“ˆ ì£¼ì‹ ê°€ì¹˜ í‰ê°€ ì™„ë£Œ\")]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a789c71d-1742-4c8d-81a2-619a6bc789ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë©”ëª¨ë¦¬ ë° ìƒíƒœ ê·¸ë˜í”„ ì´ˆê¸°í™”\n",
    "memory = MemorySaver()\n",
    "graph_builder = StateGraph(OverallState, input=InputState, output=EndState)\n",
    "\n",
    "# ë…¸ë“œ ë“±ë¡\n",
    "graph_builder.add_node(\"User Input\", user_input_node)\n",
    "graph_builder.add_node(\"Search Query Generation\", search_query_generation_node)\n",
    "graph_builder.add_node(\"Query Refinement\", query_refine_node)\n",
    "graph_builder.add_node(\"Query Loop (RAG + Web)\", query_loop_node)\n",
    "graph_builder.add_node(\"Web Fallback\", web_fallback_node)\n",
    "graph_builder.add_node(\"Stock Valuation\", stock_valuation_node)\n",
    "\n",
    "# ì—£ì§€ ì—°ê²°\n",
    "graph_builder.set_entry_point(\"User Input\")  # ì‹œì‘ ë…¸ë“œ\n",
    "graph_builder.add_edge(\"User Input\", \"Search Query Generation\")\n",
    "graph_builder.add_edge(\"Search Query Generation\", \"Query Refinement\")\n",
    "graph_builder.add_edge(\"Query Refinement\", \"Query Loop (RAG + Web)\")\n",
    "graph_builder.add_edge(\"Query Loop (RAG + Web)\", \"Stock Valuation\")\n",
    "graph_builder.add_edge(\"Stock Valuation\", END)\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98935cc2-3b2d-455b-a07a-9c01e09109fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================= calculation stock =================================\n",
      "ì£¼ì‹ ê°€ì¹˜ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. ê¶ê¸ˆí•˜ì‹  ì£¼ì‹ëª…ì„ ë§ì”€í•´ì£¼ì„¸ìš”.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  ì‚¼ì„±ì „ì\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” ì¿¼ë¦¬ ë³´ì • ê²°ê³¼:\n",
      "- ì‚¼ì„±ì „ì ë‹¹ê¸°ìˆœì´ìµ â†’ ì‚¼ì„±ì „ì ì—°ê²° ê¸°ì¤€ ë‹¹ê¸°ìˆœì´ìµ\n",
      "- ì‚¼ì„±ì „ì ë°œí–‰ì£¼ì‹ìˆ˜ â†’ ì‚¼ì„±ì „ì ë°œí–‰ì£¼ì‹ìˆ˜\n",
      "- ì‚¼ì„±ì „ì í˜„ì¬ ì£¼ê°€ â†’ ì‚¼ì„±ì „ì í˜„ì¬ ì£¼ê°€\n",
      "- ì‚¼ì„±ì „ì ìë³¸ì´ê³„ â†’ ì‚¼ì„±ì „ì ìë³¸ì´ê³„\n",
      "- ì‚¼ì„±ì „ì ììœ í˜„ê¸ˆíë¦„ â†’ ì‚¼ì„±ì „ì ììœ í˜„ê¸ˆíë¦„í‘œ\n",
      "- ì‚¼ì„±ì „ì ì˜ì—…ì´ìµ â†’ ì‚¼ì„±ì „ì ì˜ì—…ì´ìµ\n",
      "- ì‚¼ì„±ì „ì ê°€ì¤‘í‰ê· ìë³¸ë¹„ìš©(WACC) â†’ ì‚¼ì„±ì „ì ê°€ì¤‘í‰ê· ìë³¸ë¹„ìš©(WACC)\n",
      "- ì‚¼ì„±ì „ì ì˜ˆìƒë¯¸ë˜í˜„ê¸ˆíë¦„ â†’ ì‚¼ì„±ì „ì ì˜ˆìƒ ë¯¸ë˜ í˜„ê¸ˆíë¦„\n",
      "- ì‚¼ì„±ì „ì ì„±ì¥ë¥  â†’ ì‚¼ì„±ì „ì ì„±ì¥ë¥ \n",
      "- ì‚¼ì„±ì „ì ì£¼ë‹¹ë°°ë‹¹ê¸ˆ â†’ ì‚¼ì„±ì „ì ì£¼ë‹¹ ë°°ë‹¹ê¸ˆ ì§€ê¸‰ ê³„íš\n",
      "- ì‚¼ì„±ì „ì ê¸°íƒ€ ìˆ˜ìµ ê´€ë ¨ ì •ë³´ â†’ ì‚¼ì„±ì „ì ê¸°íƒ€ ìˆ˜ìµ ê´€ë ¨ ì •ë³´\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì ì—°ê²° ê¸°ì¤€ ë‹¹ê¸°ìˆœì´ìµ\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì ë°œí–‰ì£¼ì‹ìˆ˜\n",
      "âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì í˜„ì¬ ì£¼ê°€\n",
      "âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì ìë³¸ì´ê³„\n",
      "âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì ììœ í˜„ê¸ˆíë¦„í‘œ\n",
      "âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì ì˜ì—…ì´ìµ\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì ê°€ì¤‘í‰ê· ìë³¸ë¹„ìš©(WACC)\n",
      "âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì ì˜ˆìƒ ë¯¸ë˜ í˜„ê¸ˆíë¦„\n",
      "âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì ì„±ì¥ë¥ \n",
      "âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì ì£¼ë‹¹ ë°°ë‹¹ê¸ˆ ì§€ê¸‰ ê³„íš\n",
      "âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì ê¸°íƒ€ ìˆ˜ìµ ê´€ë ¨ ì •ë³´\n",
      "âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\n",
      "\n",
      "ğŸ“ˆ ì£¼ì‹ ê°€ì¹˜ í‰ê°€ ê²°ê³¼:\n",
      "---\n",
      "1. ì‚¬ìš©ëœ ì£¼ìš” ì¬ë¬´ ì§€í‘œ ìš”ì•½\n",
      "   - ìˆœì´ìµ(Net Income): 2,475ì–µì›\n",
      "   - ë°œí–‰ì£¼ì‹ìˆ˜(Shares Outstanding): 6,792,669,250ì£¼\n",
      "   - í˜„ì¬ ì£¼ê°€(Stock Price): 60,200ì›\n",
      "   - ìê¸°ìë³¸(Shareholders' Equity): 354,749.6ì–µì›\n",
      "   - ììœ í˜„ê¸ˆíë¦„(Free Cash Flow): 13.346ì¡°ì›\n",
      "   - ìš´ì˜ì´ìµ(Operating Income): 91,834ì–µì›\n",
      "   - ì„±ì¥ë¥ (Growth Rate): 62.5%\n",
      "   - ì£¼ë‹¹ ë°°ë‹¹ê¸ˆ(Dividend per Share): 20,347ë°±ë§Œì›\n",
      "   - ROE: 8.69%\n",
      "\n",
      "2. [DCF] ë°©ì‹ì— ì˜í•œ ì£¼ë‹¹ ì ì • ì£¼ê°€ ì¶”ì •\n",
      "   - ììœ í˜„ê¸ˆíë¦„(FCF): 13.346ì¡°ì› = 13,346ì–µì›\n",
      "   - ì„±ì¥ë¥ (Growth Rate): 62.5%\n",
      "   - ê°€ì •: 5ë…„ í›„ FCF ì„±ì¥ë¥ ì´ ê°ì†Œí•˜ì—¬ 3%ë¡œ ì•ˆì •í™”ëœë‹¤ê³  ê°€ì •\n",
      "   - 1ë…„ í›„ FCF = 13,346 * (1 + 0.625) = 21,688.75ì–µì›\n",
      "   - 2ë…„ í›„ FCF = 21,688.75 * (1 + 0.625) = 35,197.34ì–µì›\n",
      "   - 3ë…„ í›„ FCF = 35,197.34 * (1 + 0.625) = 57,186.67ì–µì›\n",
      "   - 4ë…„ í›„ FCF = 57,186.67 * (1 + 0.625) = 93,063.67ì–µì›\n",
      "   - 5ë…„ í›„ FCF = 93,063.67 * (1 + 0.625) = 151,882.67ì–µì›\n",
      "   - 5ë…„ í›„ FCF ì´í›„ ì•ˆì • ì„±ì¥ë¥  3% ê°€ì •\n",
      "   - Terminal Value = 151,882.67 / (0.03) = 5,062,755.67ì–µì›\n",
      "   - í• ì¸ìœ¨(WACC) ê°€ì •: 8% (ê°€ì •)\n",
      "   - DCF ê³„ì‚°:\n",
      "     - PV(FCF 1~5ë…„) = 21,688.75 / (1 + 0.08)^1 + 35,197.34 / (1 + 0.08)^2 + 57,186.67 / (1 + 0.08)^3 + 93,063.67 / (1 + 0.08)^4 + 151,882.67 / (1 + 0.08)^5\n",
      "     - PV(Terminal Value) = 5,062,755.67 / (1 + 0.08)^5\n",
      "   - ì´ PV = PV(FCF 1~5ë…„) + PV(Terminal Value)\n",
      "   - ì£¼ë‹¹ ê°€ì¹˜ = ì´ PV / ë°œí–‰ì£¼ì‹ìˆ˜\n",
      "\n",
      "3. [PER/PBR] ë°©ì‹ì— ì˜í•œ ì£¼ë‹¹ ì ì • ì£¼ê°€ ì¶”ì •\n",
      "   - PER (ì£¼ê°€ìˆ˜ìµë¹„ìœ¨) = í˜„ì¬ ì£¼ê°€ / ì£¼ë‹¹ ìˆœì´ìµ\n",
      "   - ì£¼ë‹¹ ìˆœì´ìµ(EPS) = ìˆœì´ìµ / ë°œí–‰ì£¼ì‹ìˆ˜ = 2,475ì–µì› / 6,792,669,250ì£¼ = ì•½ 0.364ì›\n",
      "   - PER = 60,200 / 0.364 = ì•½ 165,000\n",
      "   - PBR (ì£¼ê°€ìˆœìì‚°ë¹„ìœ¨) = í˜„ì¬ ì£¼ê°€ / ì£¼ë‹¹ ìˆœìì‚°\n",
      "   - ì£¼ë‹¹ ìˆœìì‚°(BPS) = ìê¸°ìë³¸ / ë°œí–‰ì£¼ì‹ìˆ˜ = 354,749.6ì–µì› / 6,792,669,250ì£¼ = ì•½ 52.2ì›\n",
      "   - PBR = 60,200 / 52.2 = ì•½ 1,152.67\n",
      "\n",
      "4. ìµœì¢… íŒë‹¨ ë° íˆ¬ìì ì°¸ê³  ì‚¬í•­\n",
      "   - DCF ë°©ì‹ì— ì˜í•œ ì£¼ê°€ëŠ” ê³„ì‚°ì´ ë³µì¡í•˜ì—¬ ì •í™•í•œ ìˆ˜ì¹˜ë¥¼ ì œê³µí•˜ê¸° ì–´ë ¤ìš°ë‚˜, ëŒ€ëµì ì¸ ì£¼ê°€ëŠ” 60,000ì› ì´ìƒìœ¼ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.\n",
      "   - PER/PBR ë°©ì‹ì— ì˜í•œ ì£¼ê°€ëŠ” ê°ê° 165,000ì›ê³¼ 1,152.67ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.\n",
      "   - í˜„ì¬ ì£¼ê°€ëŠ” 60,200ì›ì´ë¯€ë¡œ, PER/PBR ë°©ì‹ì— ì˜í•œ ì£¼ê°€ëŠ” í˜„ì¬ ì£¼ê°€ë³´ë‹¤ ìƒë‹¹íˆ ë†’ìŠµë‹ˆë‹¤.\n",
      "   - íˆ¬ììëŠ” ì‚¼ì„±ì „ìì˜ ì„±ì¥ ê°€ëŠ¥ì„±ê³¼ ì‹œì¥ ìƒí™©ì„ ê³ ë ¤í•˜ì—¬ íˆ¬ì ê²°ì •ì„ ë‚´ë¦¬ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. DCF ëª¨ë¸ì˜ ê²½ìš° ê°€ì •ì— ë”°ë¼ ê²°ê³¼ê°€ í¬ê²Œ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ì´ˆê¸° ìƒíƒœ\n",
    "initial_state = {\n",
    "    \"start_input\": \"\",\n",
    "}\n",
    "\n",
    "# ê·¸ë˜í”„ ì‹¤í–‰\n",
    "final_state = graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ad7c1b-9fd2-4119-988d-8bcbc004f8ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
