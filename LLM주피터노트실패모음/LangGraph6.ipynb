{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5961616-6a18-4434-9a23-629305af71b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY ì •ë³´ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "604baa53-a1c1-45c1-88d7-cd32702fb035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "ì£¼ì‹ë¶„ì„\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "logging.langsmith(\"ì£¼ì‹ë¶„ì„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "418728f7-666c-49d2-93b3-425a0eac62bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fastmcp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastmcp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastMCP\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fastmcp'"
     ]
    }
   ],
   "source": [
    "from fastmcp import FastMCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3375aa0e-43dd-4745-b03f-1169291c6f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Annotated, List, Dict\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.messages import HumanMessage, ToolMessage, AIMessage\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.tools.retriever import create_retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f53c0f0d-9fd8-4e45-91e6-b7a43451b1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë³¸ ë¬¸ì„œ ìˆ˜: 404\n",
      "ì¤‘ë³µ ì œê±° í›„ ë¬¸ì„œ ìˆ˜: 403\n"
     ]
    }
   ],
   "source": [
    "######## nodes.py ########\n",
    "# --- ë¬¸ì„œ ë¡œë“œ ë° ì „ì²˜ë¦¬ ---\n",
    "loader = PyMuPDFLoader(\"stock_report/[ì‚¼ì„±ì „ì]ë¶„ê¸°ë³´ê³ ì„œ(2024.11.14).pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "## : ë¬¸ì„œ ë¶„í• (Split Documents) <-----------ì¶”í›„ ë¬¸ì„œ ì œëª© ë‹¨ìœ„ ë¶„í• ë¡œ ë³€ê²½ í•„ìš”\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=500)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# ì¤‘ë³µ ì œê±°\n",
    "unique_documents = []\n",
    "seen_contents = set()\n",
    "\n",
    "for doc in split_documents:\n",
    "    content = doc.page_content.strip()\n",
    "    if content not in seen_contents:\n",
    "        seen_contents.add(content)\n",
    "        unique_documents.append(doc)\n",
    "\n",
    "print(f\"ì›ë³¸ ë¬¸ì„œ ìˆ˜: {len(split_documents)}\")\n",
    "print(f\"ì¤‘ë³µ ì œê±° í›„ ë¬¸ì„œ ìˆ˜: {len(unique_documents)}\")\n",
    "\n",
    "## ë‹¨ê³„ 3: ì„ë² ë”©(Embedding) ìƒì„±\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# ë²¡í„°ìŠ¤í† ì–´ ìƒì„±\n",
    "vectorstore = Chroma.from_documents(documents=split_documents, embedding=embeddings, persist_directory=\"stock_report/chroma_db\")\n",
    "\n",
    "# 5. ê²€ìƒ‰ê¸°(Retriever) ìƒì„±\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10e6f609-baaa-4d45-ab11-ddf777f45758",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputState(TypedDict):\n",
    "    start_input: str\n",
    "\n",
    "class QueryLoop:\n",
    "    def __init__(self, query_list):\n",
    "        self.queries = query_list\n",
    "        self.index = 0\n",
    "        self.results = {}\n",
    "        self.fallback_queries = []\n",
    "        self.unresolved_queries = []\n",
    "\n",
    "    def has_next(self):\n",
    "        return self.index < len(self.queries)\n",
    "\n",
    "    def current_query(self):\n",
    "        return self.queries[self.index]\n",
    "\n",
    "    def save_result(self, query_key, result_dict):\n",
    "        self.results[query_key] = result_dict\n",
    "        self.index += 1\n",
    "\n",
    "class OverallState(TypedDict):\n",
    "    start_input: str\n",
    "    user_input: str\n",
    "    messages: Annotated[list, add_messages]\n",
    "    query_list: List[str]\n",
    "    Stock_Value_dict: dict\n",
    "    loop: QueryLoop\n",
    "    current_query_result: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae8d5b85-eb5b-4480-a3f2-28b5aa88c8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ìš©ì ì…ë ¥ ë…¸ë“œ ì •ì˜\n",
    "def user_input_node(state: OverallState):\n",
    "    print(\"================================= calculation stock =================================\")\n",
    "    print(\"ì£¼ì‹ ê°€ì¹˜ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. ê¶ê¸ˆí•˜ì‹  ì£¼ì‹ëª…ì„ ë§ì”€í•´ì£¼ì„¸ìš”.\")\n",
    "    user_input = input(\"User: \")\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"user_input\": user_input,\n",
    "        \"messages\": [HumanMessage(content=user_input)],\n",
    "        \"Stock_Value_dict\": {},  # ë‚˜ì¤‘ì— ì—¬ê¸°ì— ë°ì´í„° ì±„ì›Œì§\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3f6fa78-2e83-44df-9483-adfd9b2429d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_query_generation_node(state: OverallState) -> OverallState:\n",
    "    user_input = state[\"user_input\"]\n",
    "\n",
    "    base_queries = [\n",
    "        \"ì—°ê²° ê¸°ì¤€ ë‹¹ê¸°ìˆœì´ìµ\",\n",
    "        \"ë°œí–‰ì£¼ì‹ìˆ˜\",\n",
    "        \"í˜„ì¬ ì£¼ê°€\",\n",
    "        \"ìë³¸ì´ê³„\",\n",
    "        \"ììœ í˜„ê¸ˆíë¦„\",\n",
    "        \"ì˜ì—…ì´ìµ\",\n",
    "        \"ê°€ì¤‘í‰ê· ìë³¸ë¹„ìš©(WACC)\",\n",
    "        \"ì˜ˆìƒ ë¯¸ë˜ í˜„ê¸ˆíë¦„\",\n",
    "        \"ì„±ì¥ë¥ \",\n",
    "        \"ì£¼ë‹¹ ë°°ë‹¹ê¸ˆ\",\n",
    "        \"ê¸°íƒ€ ìˆ˜ìµ ê´€ë ¨ ì •ë³´\"\n",
    "    ]\n",
    "\n",
    "    # ì‚¬ìš©ìì˜ ê¸°ì—…ëª…ì„ ì•ì— ë¶™ì—¬ì„œ ì „ì²´ ì¿¼ë¦¬ ìƒì„±\n",
    "    query_list = [f\"{user_input} {q}\" for q in base_queries]\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"query_list\": query_list\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20e3f54e-038b-4744-b3ab-24cfb1310988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_query_loop_node(state: OverallState) -> OverallState:\n",
    "    query_list = state[\"query_list\"]\n",
    "    loop = QueryLoop(query_list)\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"loop\": loop\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b886eafc-21da-4d03-b0ff-a869aa711a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_next_query_node(state: OverallState) -> str:\n",
    "    if state[\"loop\"].has_next():\n",
    "        return \"continue\"\n",
    "    else:\n",
    "        return \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d52474d2-57ca-4b9b-b06d-33f9123739e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query_node(state: OverallState) -> OverallState:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "    loop = state[\"loop\"]\n",
    "    query = loop.current_query()\n",
    "    \n",
    "    print(f\"\\nğŸ” [RAG 1ì°¨ ê²€ìƒ‰] {query}\")\n",
    "    \n",
    "    # --- 1. RAG 1ì°¨ ê²€ìƒ‰ ---\n",
    "    try:\n",
    "        docs = list({doc.page_content.strip() for doc in retriever.invoke(query)})\n",
    "        context = \"\\n\\n\".join(docs)[:3000]\n",
    "    except Exception as e:\n",
    "        print(f\"â— RAG 1ì°¨ ê²€ìƒ‰ ì‹¤íŒ¨: {e}\")\n",
    "        context = \"\"\n",
    "\n",
    "    # --- 2. ì¿¼ë¦¬ ë¦¬íŒŒì¸ (context ê¸°ë°˜, LLM ì‚¬ìš©) ---\n",
    "    refined_query = query\n",
    "    if context.strip():\n",
    "        refined_query = query_refiner(context=context, original_query=query, llm=llm)\n",
    "        print(f\"ğŸ” ì¿¼ë¦¬ ë¦¬íŒŒì¸: {query} â†’ {refined_query}\")\n",
    "\n",
    "    # --- 3. RAG 2ì°¨ ê²€ìƒ‰ ---\n",
    "    print(f\"\\nğŸ” [RAG 2ì°¨ ê²€ìƒ‰] {refined_query}\")\n",
    "    try:\n",
    "        refined_docs = list({doc.page_content.strip() for doc in retriever.invoke(refined_query)})\n",
    "        refined_context = \"\\n\\n\".join(refined_docs)[:3000]\n",
    "    except Exception as e:\n",
    "        print(f\"â— RAG 2ì°¨ ê²€ìƒ‰ ì‹¤íŒ¨: {e}\")\n",
    "        refined_context = \"\"\n",
    "\n",
    "    # --- 4. context ìš”ì•½ ë° key ê°’ ì¶”ì¶œ ---\n",
    "    parsed = summarize_context(refined_context, llm)\n",
    "    print(f\"ğŸ“„ ìš”ì•½ ì¶”ì¶œ ê²°ê³¼: {parsed}\")\n",
    "\n",
    "    # --- 5. ê²°ê³¼ë§Œ ì €ì¥ (ì›¹ fallbackì€ ë‹¤ìŒ ë…¸ë“œì—ì„œ íŒë‹¨) ---\n",
    "    return {\n",
    "        **state,\n",
    "        \"current_query_result\": parsed\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "143ed6f6-49e8-4ea7-929c-9c69ec378991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_refiner(context: str, original_query: str, llm: ChatOpenAI) -> str:\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"\n",
    "ë‹¹ì‹ ì€ ê¸°ì—… ë³´ê³ ì„œ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¿¼ë¦¬ë¥¼ ë³´ì •í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "\n",
    "[ì…ë ¥ ì¿¼ë¦¬]ëŠ” ë„ˆë¬´ ì¼ë°˜ì ì¼ ìˆ˜ ìˆìœ¼ë‹ˆ, [ë¬¸ë§¥(context)]ì„ ì°¸ê³ í•˜ì—¬\n",
    "ì‹¤ì œ ë³´ê³ ì„œì— ë” ì˜ ë§¤ì¹­ë˜ëŠ” ëª…í™•í•œ ì¿¼ë¦¬ë¡œ ë°”ê¿”ì£¼ì„¸ìš”.\n",
    "\n",
    "ê°€ëŠ¥í•˜ë©´ ë³´ê³ ì„œì— ìì£¼ ë‚˜ì˜¤ëŠ” ìš©ì–´ (ì˜ˆ: 'ìš”ì•½ ì¬ë¬´ì œí‘œ', 'ì—°ê²° ì†ìµê³„ì‚°ì„œ', 'í˜„ê¸ˆíë¦„í‘œ', 'ì§€ë°°ê¸°ì—… ê·€ì† ë‹¹ê¸°ìˆœì´ìµ') ë“±ì„ ë°˜ì˜í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ë°˜ë“œì‹œ ë³´ì •ëœ ì¿¼ë¦¬ í•œ ì¤„ë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”.\n",
    "\"\"\"),\n",
    "        (\"human\", f\"\"\"\n",
    "[ì…ë ¥ ì¿¼ë¦¬]\n",
    "{original_query}\n",
    "\n",
    "[ë¬¸ë§¥]\n",
    "{context[:1500]}\n",
    "\n",
    "[ë³´ì •ëœ ì¿¼ë¦¬]\n",
    "\"\"\")\n",
    "    ])\n",
    "\n",
    "    messages = prompt.format_messages()\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    return response.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af735c33-cf9f-4b7e-821b-0a76eb5f2ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_context(context: str, llm: ChatOpenAI) -> dict:\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"\n",
    "ë‹¹ì‹ ì€ ê¸°ì—…ì˜ ì¬ë¬´ ë°ì´í„°ë¥¼ ì •ë¦¬í•˜ëŠ” ì „ë¬¸ AIì…ë‹ˆë‹¤.\n",
    "\n",
    "ì…ë ¥ìœ¼ë¡œ ì œê³µëœ ê¸°ì—… ë³´ê³ ì„œì˜ ì¼ë¶€(context)ë¥¼ ì½ê³ ,  \n",
    "ë‹¤ìŒ í•­ëª© ì¤‘ ë¬¸ì„œì— ì–¸ê¸‰ëœ ê°’ì´ ìˆìœ¼ë©´ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”.  \n",
    "ì—†ë‹¤ë©´ 'ì—†ìŒ'ì´ë¼ê³  ì ìœ¼ì„¸ìš”.\n",
    "\n",
    "í•­ëª©:\n",
    "- Net_Income (ë‹¹ê¸°ìˆœì´ìµ)\n",
    "- Operating_income (ì˜ì—…ì´ìµ)\n",
    "- Free_cash_flow (ììœ í˜„ê¸ˆíë¦„)\n",
    "- WACC (ê°€ì¤‘í‰ê· ìë³¸ë¹„ìš©)\n",
    "- Future_cash_flow (ì˜ˆìƒ ë¯¸ë˜ í˜„ê¸ˆ íë¦„)\n",
    "- Growth_rate (ì„±ì¥ë¥ )\n",
    "- Dividend_per_share (ì£¼ë‹¹ ë°°ë‹¹ê¸ˆ)\n",
    "- ROE (ìê¸°ìë³¸ì´ìµë¥ )\n",
    "- Shares_outstanding (ë°œí–‰ ì£¼ì‹ ìˆ˜)\n",
    "- Stock_price (í˜„ì¬ ì£¼ê°€)\n",
    "- Equity (ìê¸°ìë³¸)\n",
    "\n",
    "ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON í˜•ì‹ì˜ íŒŒì´ì¬ ë”•ì…”ë„ˆë¦¬ë¡œ í•´ì£¼ì„¸ìš”.\n",
    "\"\"\"),\n",
    "        (\"human\", f\"\"\"\n",
    "[ë¬¸ì„œ ë‚´ìš©]\n",
    "{context[:3000]}\n",
    "\"\"\")\n",
    "    ])\n",
    "\n",
    "    messages = prompt.format_messages()\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    try:\n",
    "        content = response.content.strip()\n",
    "        cleaned = re.sub(r\"^```(?:json)?\\n|\\n```$\", \"\", content)\n",
    "        parsed = json.loads(cleaned)\n",
    "    except Exception as e:\n",
    "        print(f\"â— ìš”ì•½ ì‹¤íŒ¨: {e}\")\n",
    "        parsed = {}\n",
    "\n",
    "    return parsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5decad7-bdbc-4640-8229-026d4713533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_loop_state_node(state: OverallState) -> OverallState:\n",
    "    loop = state[\"loop\"]\n",
    "    query = loop.current_query()\n",
    "    parsed = state[\"current_query_result\"]\n",
    "    stock_data = state[\"Stock_Value_dict\"]\n",
    "\n",
    "    # ê²°ê³¼ ì €ì¥ (QueryLoop ë‚´ë¶€ results ë”•ì…”ë„ˆë¦¬ ì—…ë°ì´íŠ¸)\n",
    "    loop.save_result(query_key=query, result_dict=parsed)\n",
    "\n",
    "    # ê¸°ì¡´ stock_dataì— ë³‘í•© (ì—†ìœ¼ë©´ ì €ì¥, ì´ë¯¸ ìˆìœ¼ë©´ ìœ ì§€)\n",
    "    for k, v in parsed.items():\n",
    "        if k not in stock_data or stock_data[k] == \"ì—†ìŒ\":\n",
    "            stock_data[k] = v\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"loop\": loop,\n",
    "        \"Stock_Value_dict\": stock_data\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c8d436b-5343-49a7-b235-7fe770e23650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_search_node(state: OverallState) -> OverallState:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    tavily = TavilySearchResults(max_results=3)\n",
    "\n",
    "    loop = state[\"loop\"]\n",
    "    query = loop.current_query()\n",
    "    parsed = state[\"current_query_result\"]\n",
    "    stock_data = state[\"Stock_Value_dict\"]\n",
    "\n",
    "    print(f\"ğŸŒ ì›¹ ë³´ì™„ ì‹œë„ ì¤‘: {query}\")\n",
    "\n",
    "    # 1. parsed ì¤‘ 'ì—†ìŒ'ì¸ keyê°€ ìˆëŠ” ê²½ìš°ë§Œ ë³´ì™„ ì‹œë„\n",
    "    if all(v != \"ì—†ìŒ\" for v in parsed.values()):\n",
    "        print(\"âœ… ëª¨ë“  ê°’ì´ ì±„ì›Œì ¸ ìˆìŒ â†’ ì›¹ ë³´ì™„ ìƒëµ\")\n",
    "        return state\n",
    "\n",
    "    # 2. ì›¹ ê²€ìƒ‰\n",
    "    try:\n",
    "        web_result = tavily.invoke({\"query\": query})\n",
    "        web_context = \"\\n\\n\".join([\n",
    "            doc.get(\"content\", \"\") for doc in (web_result.get(\"documents\", []) if isinstance(web_result, dict) else web_result)\n",
    "        ])[:3000]\n",
    "\n",
    "        if web_context.strip():\n",
    "            web_parsed = summarize_context(web_context, llm)\n",
    "\n",
    "            # 3. ê¸°ì¡´ parsedì˜ 'ì—†ìŒ'ì¸ í•­ëª©ë§Œ ì—…ë°ì´íŠ¸\n",
    "            for k, v in web_parsed.items():\n",
    "                if parsed.get(k, \"ì—†ìŒ\") == \"ì—†ìŒ\" and v != \"ì—†ìŒ\":\n",
    "                    parsed[k] = v\n",
    "                    stock_data[k] = v\n",
    "\n",
    "            print(f\"ğŸ§© ì›¹ ê²€ìƒ‰ ë³´ì™„ ê²°ê³¼: {parsed}\")\n",
    "        else:\n",
    "            print(\"âš ï¸ ì›¹ context ì—†ìŒ\")\n",
    "    except Exception as e:\n",
    "        print(f\"â— ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"current_query_result\": parsed,\n",
    "        \"Stock_Value_dict\": stock_data\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0af635f2-1ebb-4dcd-9bb7-349d0cc9c930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_query_refine_node(state: OverallState) -> OverallState:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    query = state[\"loop\"].current_query()\n",
    "    parsed = state[\"current_query_result\"]\n",
    "\n",
    "    # âœ… ëª¨ë“  ê°’ì´ ì±„ì›Œì ¸ ìˆìœ¼ë©´ ë¦¬íŒŒì¸ ìƒëµ\n",
    "    if all(v != \"ì—†ìŒ\" for v in parsed.values()):\n",
    "        print(\"âœ… ëª¨ë“  ê°’ì´ ì±„ì›Œì ¸ ìˆìŒ â†’ ì›¹ ì¿¼ë¦¬ ë¦¬íŒŒì¸ ìƒëµ\")\n",
    "        return {**state, \"refined_web_query\": query}\n",
    "\n",
    "    # âœ… ì¿¼ë¦¬ ë¦¬íŒŒì¸ ìš”ì²­\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"\n",
    "ë‹¹ì‹ ì€ ì˜¨ë¼ ê²€ìƒ‰ ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì…ë ¥ ì¿¼ë¦¬ë¥¼ ë³´ê³ , ê²€ìƒ‰ ì—”ì§„ì— ë” ì˜ ë§ë„ë¡ **ì •í™•í•˜ê³  êµ¬ì²´ì ì¸ í‘œí˜„**ìœ¼ë¡œ ë°”ê¿”ì£¼ì„¸ìš”.\n",
    "ê°€ëŠ¥í•˜ë©´ ì‹¤ì œ ì¬ë¬´ ìš©ì–´ë‚˜ ê´€ë ¨ ë³´ê³ ì„œì—ì„œ ì“°ì´ëŠ” í‘œí˜„ì„ í¬í•¨í•˜ì„¸ìš”.\n",
    "\n",
    "- ìˆ«ì ë‹¨ìœ„ë‚˜ íŠ¹ì • ì¬ë¬´ ì§€í‘œë¥¼ ëª…í™•í•˜ê²Œ ê¸°ìˆ \n",
    "- \"ì˜ˆìƒ\" â†’ \"ì „ë§\", \"ì¶”ì •\", \"ê°€ì´ë˜ìŠ¤\"\n",
    "- \"ììœ í˜„ê¸ˆíë¦„\" â†’ \"FCF\", \"í˜„ê¸ˆíë¦„í‘œ\", \"ìˆœí˜„ê¸ˆíë¦„\"\n",
    "- ë„ˆë¬´ ì¼ë°˜ì ì¸ ë‹¨ì–´ëŠ” ì§€ì–‘ (ì˜ˆ: ìˆ˜ìµ, ì‹¤ì , ì´ìµ)\n",
    "\n",
    "ì…ë ¥ ì¿¼ë¦¬:\n",
    "{query}\n",
    "\n",
    "ë³´ì •ëœ ì¿¼ë¦¬ë¥¼ í•œ ì¤„ë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n",
    "\"\"\")\n",
    "    ])\n",
    "\n",
    "    messages = prompt.format_messages(query=query)\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    refined_query = response.content.strip()\n",
    "\n",
    "    print(f\"ğŸ” ì›¹ ì¿¼ë¦¬ ì¬ì‘ì„±: {query} â†’ {refined_query}\")\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"refined_web_query\": refined_query\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91ed8d9e-6274-4864-b4e4-0d4d6bf55c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_search_retry_node(state: OverallState) -> OverallState:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    tavily = TavilySearchResults(max_results=3)\n",
    "\n",
    "    refined_query = state.get(\"refined_web_query\", \"\")\n",
    "    parsed = state[\"current_query_result\"]\n",
    "    stock_data = state[\"Stock_Value_dict\"]\n",
    "\n",
    "    if not refined_query:\n",
    "        print(\"â— refined_web_query ì—†ìŒ â†’ ì›¹ ì¬ê²€ìƒ‰ ìƒëµ\")\n",
    "        return state\n",
    "\n",
    "    # ë³´ì™„í•  í•­ëª©ì´ ì—†ëŠ” ê²½ìš° ì¢…ë£Œ\n",
    "    if all(v != \"ì—†ìŒ\" for v in parsed.values()):\n",
    "        print(\"âœ… ëª¨ë“  í•­ëª©ì´ ì´ë¯¸ ì±„ì›Œì§ â†’ ì¬ê²€ìƒ‰ ë¶ˆí•„ìš”\")\n",
    "        return state\n",
    "\n",
    "    print(f\"ğŸŒ ë³´ì • ì¿¼ë¦¬ë¡œ ì›¹ ì¬ê²€ìƒ‰: {refined_query}\")\n",
    "\n",
    "    try:\n",
    "        web_result = tavily.invoke({\"query\": refined_query})\n",
    "        web_context = \"\\n\\n\".join([\n",
    "            doc.get(\"content\", \"\") for doc in (web_result.get(\"documents\", []) if isinstance(web_result, dict) else web_result)\n",
    "        ])[:3000]\n",
    "\n",
    "        if web_context.strip():\n",
    "            web_parsed = summarize_context(web_context, llm)\n",
    "\n",
    "            # 'ì—†ìŒ'ì¸ í•­ëª©ë§Œ ë³´ì™„\n",
    "            for k, v in web_parsed.items():\n",
    "                if parsed.get(k, \"ì—†ìŒ\") == \"ì—†ìŒ\" and v != \"ì—†ìŒ\":\n",
    "                    parsed[k] = v\n",
    "                    stock_data[k] = v\n",
    "\n",
    "            print(f\"âœ… ì›¹ ì¬ê²€ìƒ‰ ë³´ì™„ ì™„ë£Œ: {parsed}\")\n",
    "        else:\n",
    "            print(\"âš ï¸ ì›¹ ì¬ê²€ìƒ‰ context ì—†ìŒ\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"â— ì›¹ ì¬ê²€ìƒ‰ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"current_query_result\": parsed,\n",
    "        \"Stock_Value_dict\": stock_data\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41c6c2f1-2fd3-4356-9795-33293eaaf62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculation_node(state: OverallState) -> OverallState:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    stock_data = state[\"Stock_Value_dict\"]\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"\n",
    "ë‹¹ì‹ ì€ ê¸°ì—… ê°€ì¹˜ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ìŒì€ í•œ ê¸°ì—…ì˜ ì£¼ìš” ì¬ë¬´ ì§€í‘œì…ë‹ˆë‹¤. ì´ ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒì„ ìˆ˜í–‰í•˜ì„¸ìš”:\n",
    "\n",
    "1. DCF ë°©ì‹ì— ë”°ë¥¸ ì ì • ì£¼ë‹¹ ê°€ì¹˜ ì¶”ì •  \n",
    "2. PER ë° PBR ë°©ì‹ì˜ í˜„ì¬ ë°¸ë¥˜ì—ì´ì…˜ ë¶„ì„  \n",
    "3. í•µì‹¬ ìˆ˜ì¹˜ ë° ê°€ì • ìš”ì•½  \n",
    "4. íˆ¬ììì—ê²Œ ì¤„ ìˆ˜ ìˆëŠ” ê°„ë‹¨í•œ ì‹œì‚¬ì \n",
    "\n",
    "ì¶œë ¥ í˜•ì‹ì€ ê¹”ë”í•œ ë³´ê³ ì„œ í˜•ì‹ìœ¼ë¡œ, í•­ëª©ë³„ë¡œ êµ¬ë¶„í•´ì„œ ì„¤ëª…í•˜ì„¸ìš”.\n",
    "\"\"\"),\n",
    "        (\"human\", f\"\"\"\n",
    "[ì…ë ¥ ì¬ë¬´ ì§€í‘œ]\n",
    "{json.dumps(stock_data, ensure_ascii=False, indent=2)}\n",
    "\n",
    "ì´ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í‰ê°€ë¥¼ ì‹œì‘í•˜ì„¸ìš”.\n",
    "\"\"\")\n",
    "    ])\n",
    "\n",
    "    messages = prompt.format_messages()\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"messages\": messages + [AIMessage(content=response.content)],\n",
    "        \"final_result\": {\"LLM_summary\": response.content}\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0e971d7-9df2-4b0b-9ae2-7ec6a78533c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_node(state: OverallState) -> OverallState:\n",
    "    print(\"================================= FINAL REPORT =================================\")\n",
    "    \n",
    "    # LLMì´ ì‘ì„±í•œ ë¶„ì„ ìš”ì•½ì´ ìˆìœ¼ë©´ ì¶œë ¥\n",
    "    final_summary = state.get(\"final_result\", {}).get(\"LLM_summary\", None)\n",
    "    if final_summary:\n",
    "        print(final_summary)\n",
    "    else:\n",
    "        print(\"â—ìµœì¢… ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì¼ë¶€ ë‹¨ê³„ì—ì„œ ë¬¸ì œê°€ ë°œìƒí–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    print(\"âœ… ì£¼ì‹ ê°€ì¹˜ í‰ê°€ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94d9a62e-9490-4172-be21-466b5d074736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ì „ì²´ ìƒíƒœ ì •ì˜\n",
    "workflow = StateGraph(OverallState)\n",
    "\n",
    "# 2. ìˆœì°¨ ë…¸ë“œ ì¶”ê°€\n",
    "workflow.add_node(\"User Input\", user_input_node)\n",
    "workflow.add_node(\"Search Query Generation\", search_query_generation_node)\n",
    "workflow.add_node(\"Init Loop\", init_query_loop_node)\n",
    "\n",
    "workflow.add_node(\"Process Query\", process_query_node)\n",
    "workflow.add_node(\"Update State\", update_loop_state_node)\n",
    "workflow.add_node(\"Web Search\", web_search_node)\n",
    "workflow.add_node(\"Web Query Refine\", web_query_refine_node)\n",
    "workflow.add_node(\"Web Search Retry\", web_search_retry_node)\n",
    "workflow.add_node(\"Calculation\", calculation_node)\n",
    "workflow.add_node(\"End\", end_node)\n",
    "\n",
    "# 3. ì¡°ê±´ ë¶„ê¸° ë…¸ë“œ (ë£¨í”„ ì œì–´)\n",
    "workflow.add_conditional_edges(\n",
    "    \"Init Loop\",\n",
    "    has_next_query_node,\n",
    "    {\n",
    "        \"continue\": \"Process Query\",\n",
    "        \"done\": \"Calculation\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# 4. ë…¸ë“œ ì—°ê²° ì •ì˜\n",
    "workflow.set_entry_point(\"User Input\")\n",
    "workflow.add_edge(\"User Input\", \"Search Query Generation\")\n",
    "workflow.add_edge(\"Search Query Generation\", \"Init Loop\")\n",
    "\n",
    "workflow.add_edge(\"Process Query\", \"Update State\")\n",
    "workflow.add_edge(\"Update State\", \"Web Search\")\n",
    "workflow.add_edge(\"Web Search\", \"Web Query Refine\")\n",
    "workflow.add_edge(\"Web Query Refine\", \"Web Search Retry\")\n",
    "\n",
    "workflow.add_edge(\"Calculation\", \"End\")\n",
    "workflow.add_edge(\"End\", END)\n",
    "\n",
    "# 5. ê·¸ë˜í”„ ë¹Œë“œ\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9f5163d-97ad-4f76-a534-ff82dae582ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================= calculation stock =================================\n",
      "ì£¼ì‹ ê°€ì¹˜ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. ê¶ê¸ˆí•˜ì‹  ì£¼ì‹ëª…ì„ ë§ì”€í•´ì£¼ì„¸ìš”.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  ì‚¼ì„±ì „ì\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” [RAG 1ì°¨ ê²€ìƒ‰] ì‚¼ì„±ì „ì ì—°ê²° ê¸°ì¤€ ë‹¹ê¸°ìˆœì´ìµ\n",
      "ğŸ” ì¿¼ë¦¬ ë¦¬íŒŒì¸: ì‚¼ì„±ì „ì ì—°ê²° ê¸°ì¤€ ë‹¹ê¸°ìˆœì´ìµ â†’ ì‚¼ì„±ì „ì ì—°ê²° ì†ìµê³„ì‚°ì„œ ê¸°ì¤€ ë‹¹ê¸°ìˆœì´ìµ\n",
      "\n",
      "ğŸ” [RAG 2ì°¨ ê²€ìƒ‰] ì‚¼ì„±ì „ì ì—°ê²° ì†ìµê³„ì‚°ì„œ ê¸°ì¤€ ë‹¹ê¸°ìˆœì´ìµ\n",
      "ğŸ“„ ìš”ì•½ ì¶”ì¶œ ê²°ê³¼: {'Net_Income': 261045230, 'Operating_income': 26233258, 'Free_cash_flow': 'ì—†ìŒ', 'WACC': 'ì—†ìŒ', 'Future_cash_flow': 'ì—†ìŒ', 'Growth_rate': 'ì—†ìŒ', 'Dividend_per_share': 'ì—†ìŒ', 'ROE': 'ì—†ìŒ', 'Shares_outstanding': 'ì—†ìŒ', 'Stock_price': 'ì—†ìŒ', 'Equity': 386281363}\n",
      "ğŸŒ ì›¹ ë³´ì™„ ì‹œë„ ì¤‘: ì‚¼ì„±ì „ì ë°œí–‰ì£¼ì‹ìˆ˜\n",
      "ğŸ§© ì›¹ ê²€ìƒ‰ ë³´ì™„ ê²°ê³¼: {'Net_Income': 261045230, 'Operating_income': 26233258, 'Free_cash_flow': 'ì—†ìŒ', 'WACC': 'ì—†ìŒ', 'Future_cash_flow': 'ì—†ìŒ', 'Growth_rate': 'ì—†ìŒ', 'Dividend_per_share': 'ì—†ìŒ', 'ROE': 'ì—†ìŒ', 'Shares_outstanding': 6736, 'Stock_price': 'ì—†ìŒ', 'Equity': 386281363}\n",
      "ğŸ” ì›¹ ì¿¼ë¦¬ ì¬ì‘ì„±: ì‚¼ì„±ì „ì ë°œí–‰ì£¼ì‹ìˆ˜ â†’ ì‚¼ì„±ì „ì ë°œí–‰ì£¼ì‹ìˆ˜ ë° ì£¼ì‹ êµ¬ì¡° ë¶„ì„\n",
      "â— refined_web_query ì—†ìŒ â†’ ì›¹ ì¬ê²€ìƒ‰ ìƒëµ\n"
     ]
    }
   ],
   "source": [
    "# ì´ˆê¸° ìƒíƒœ\n",
    "initial_state = {\n",
    "    \"start_input\": \"\",\n",
    "}\n",
    "\n",
    "# ê·¸ë˜í”„ ì‹¤í–‰\n",
    "final_state = graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fe5ec8-a41f-4d41-b084-9a79f975eb7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
