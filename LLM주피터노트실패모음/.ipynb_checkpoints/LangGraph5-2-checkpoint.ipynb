{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66aeb681-0452-4b25-a9fd-e24a5ed844d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY ì •ë³´ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6603e3ad-26d9-4388-8553-42d9946855e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "ì£¼ì‹ë¶„ì„\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "logging.langsmith(\"ì£¼ì‹ë¶„ì„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d675de64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryLoop:\n",
    "    def __init__(self, query_list):\n",
    "        self.queries = query_list\n",
    "        self.index = 0\n",
    "        self.results = {}\n",
    "        self.fallback_queries = []\n",
    "\n",
    "    def has_next(self):\n",
    "        return self.index < len(self.queries)\n",
    "\n",
    "    def next_query(self):\n",
    "        return self.queries[self.index]\n",
    "\n",
    "    def save_result(self, query_key, result_dict):\n",
    "        self.results[query_key] = result_dict\n",
    "        self.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa766e47-1da0-4d73-bd79-86ef18cb17cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Annotated, List, Dict\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.messages import HumanMessage, ToolMessage, AIMessage\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.tools.retriever import create_retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "053180a3-c4cf-4e3c-a1df-9c9dea6a0184",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## states ì •ì˜ ########\n",
    "class InputState(TypedDict):\n",
    "    start_input: str\n",
    "\n",
    "class OverallState(TypedDict):\n",
    "    user_input: str\n",
    "    messages: Annotated[list, add_messages]\n",
    "    Stock_Value_dict: dict\n",
    "    query_list: List[str]\n",
    "\n",
    "class EndState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    query_list: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5299c4dd-a103-4a39-af77-78f9f74fdd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ìš©ì ì…ë ¥ ë…¸ë“œ ì •ì˜\n",
    "def user_input_node(state: InputState):\n",
    "    print(\"================================= calculation stock =================================\")\n",
    "    print(\"ì£¼ì‹ ê°€ì¹˜ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. ì‚¼ì„±ì „ì ì…ë ¥\")\n",
    "    user_input = input(\"User: \")\n",
    "\n",
    "    return {\n",
    "        \"user_input\": user_input,\n",
    "        \"messages\": [(\"user\", user_input)],\n",
    "        \"Stock_Value_dict\": {},  # ë‚˜ì¤‘ì— ì—¬ê¸°ì— ë°ì´í„° ì±„ì›Œì§\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09d5d5a5-69a0-4ded-8007-1a5b15803893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_query_generation_node(state: OverallState):\n",
    "    user_input = state[\"user_input\"]\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ê¸ˆìœµ ì •ë³´ë¥¼ ì°¾ê¸° ìœ„í•œ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\"),\n",
    "        (\"human\", '''\n",
    "ì‚¬ìš©ì ì…ë ¥: \"{user_input}\"ì„ ì°¸ê³ í•˜ì—¬ ì•„ë˜ ë‚´ìš©ì— ëŒ€í•´ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.\n",
    "  \"ë‹¹ê¸°ìˆœì´ìµ\",\n",
    "  \"ë°œí–‰ì£¼ì‹ìˆ˜\",\n",
    "  \"í˜„ì¬ ì£¼ê°€\",\n",
    "  \"ìë³¸ì´ê³„\",\n",
    "  \"ììœ í˜„ê¸ˆíë¦„\",\n",
    "  \"ì˜ì—…ì´ìµ\",\n",
    "  \"ê°€ì¤‘í‰ê· ìë³¸ë¹„ìš©(WACC)\",\n",
    "  \"ì˜ˆìƒë¯¸ë˜í˜„ê¸ˆíë¦„\",\n",
    "  \"ì„±ì¥ë¥ \",\n",
    "  \"ì£¼ë‹¹ë°°ë‹¹ê¸ˆ\",\n",
    "  \"ê¸°íƒ€ ìˆ˜ìµ ê´€ë ¨ ì •ë³´\"\n",
    "ì¶œë ¥ í˜•ì‹ì€ ë°˜ë“œì‹œ JSON ë°°ì—´ì…ë‹ˆë‹¤. \n",
    "''')\n",
    "    ])\n",
    "\n",
    "    messages = prompt.format_messages(user_input=user_input)\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    try:\n",
    "        cleaned = re.sub(r\"^```(?:json)?\\n|\\n```$\", \"\", response.content.strip())\n",
    "        query_list = json.loads(cleaned)\n",
    "    except Exception as e:\n",
    "        print(f\"â— ê²€ìƒ‰ ì¿¼ë¦¬ íŒŒì‹± ì‹¤íŒ¨: {e}\")\n",
    "        query_list = []\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"query_list\": query_list\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d91186b6-f6a4-4b8f-977e-bfdd3ec9fb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_refine_node(state: dict) -> dict:\n",
    "    original_queries = state.get(\"query_list\", [])\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "\n",
    "    # ğŸ”¹ few-shot ì˜ˆì‹œ\n",
    "    examples = [\n",
    "        {\n",
    "            \"input\": [\"ì‚¼ì„±ì „ì ë‹¹ê¸°ìˆœì´ìµ\", \"ì‚¼ì„±ì „ì ë°œí–‰ì£¼ì‹ìˆ˜\"],\n",
    "            \"output\": [\"ì‚¼ì„±ì „ì 2025ë…„ ì—°ê²° ê¸°ì¤€ ë‹¹ê¸°ìˆœì´ìµ\", \"ì‚¼ì„±ì „ì 2025ë…„ ë°œí–‰ì£¼ì‹ìˆ˜\"]\n",
    "        },\n",
    "        {\n",
    "            \"input\": [\"LGì—ë„ˆì§€ì†”ë£¨ì…˜ ì˜ì—…ì´ìµ\", \"LGì—ë„ˆì§€ì†”ë£¨ì…˜ ì„±ì¥ë¥ \"],\n",
    "            \"output\": [\"LGì—ë„ˆì§€ì†”ë£¨ì…˜ 2025ë…„ ì—°ê²° ê¸°ì¤€ ì˜ì—…ì´ìµ\", \"LGì—ë„ˆì§€ì†”ë£¨ì…˜ 2025ë…„ ì˜ˆìƒ ì„±ì¥ë¥ \"]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    few_shot_format = \"\\n\\n\".join([\n",
    "        f\"ì…ë ¥: {ex['input']}\\në³´ì • ê²°ê³¼: {ex['output']}\"\n",
    "        for ex in examples\n",
    "    ])\n",
    "\n",
    "    # âœ… í”„ë¡¬í”„íŠ¸ ì •ì˜\n",
    "    refine_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", f\"\"\"\n",
    "ë‹¹ì‹ ì€ ê¸°ì—…ì˜ ê³µì‹œ ë³´ê³ ì„œë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ ì¿¼ë¦¬ë¥¼ ì •ì œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì‚¬ìš©ìê°€ ì œê³µí•œ ì¿¼ë¦¬ëŠ” ë‹¤ì†Œ ì¼ë°˜ì ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ,\n",
    "í•´ë‹¹ í•­ëª©ì´ ê¸°ì—… ë³´ê³ ì„œ ìƒ ì‹¤ì œ ë¬¸ë‹¨ ì œëª©, í‘œ ì œëª©, í•­ëª©ëª…ì— ë” ì˜ ë§¤ì¹­ë˜ë„ë¡\n",
    "ì •í™•í•˜ê³  ëª…í™•í•˜ê²Œ ë³´ì •í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ì˜ˆì‹œ few-shot:\n",
    "{few_shot_format}\n",
    "\n",
    "ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì¿¼ë¦¬ ëª©ë¡ì…ë‹ˆë‹¤:\n",
    "{{query_list}}\n",
    "\n",
    "ê°€ëŠ¥í•˜ë©´ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ ì´ìƒì˜ ê¸°ì¤€ì„ ë°˜ì˜í•˜ì„¸ìš”:\n",
    "- \"ìš”ì•½ ì¬ë¬´ì œí‘œ\", \"ì§€ë°°ê¸°ì—… ì†Œìœ ì£¼\", \"ì—°ê²° ì†ìµê³„ì‚°ì„œ\", \"í˜„ê¸ˆíë¦„í‘œ\" ê°™ì€ ì‹¤ì œ ì¬ë¬´í‘œ ì œëª©ì„ í¬í•¨\n",
    "- ìˆ˜ì¹˜ê°€ í¬í•¨ëœ í‘œë‚˜ ë¬¸ë‹¨ê³¼ ì§ì ‘ ë§¤ì¹­ë˜ëŠ” ëª…í™•í•œ í‚¤ì›Œë“œ ì‚¬ìš©\n",
    "- ë„ˆë¬´ ì¼ë°˜ì ì¸ í‘œí˜„(ì˜ˆ: 'ìˆœì´ìµ') ëŒ€ì‹  ê³µì‹ ëª…ì¹­(ì˜ˆ: 'ê·€ì† ì†ìµ') ì‚¬ìš©\n",
    "\n",
    "ì•„ë˜ì— JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œ ë³´ì •ëœ ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n",
    "ì˜ˆ: [\"...\", \"...\"]\n",
    "\"\"\")\n",
    "    ])\n",
    "\n",
    "    # âœ… í”„ë¡¬í”„íŠ¸ ë©”ì‹œì§€ ìƒì„±\n",
    "    messages = refine_prompt.format_messages(\n",
    "        query_list=json.dumps(original_queries, ensure_ascii=False)\n",
    "    )\n",
    "\n",
    "    # âœ… LLM í˜¸ì¶œ\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    # âœ… ì‘ë‹µ ì²˜ë¦¬\n",
    "    try:\n",
    "        cleaned = re.sub(r\"^```(?:json)?\\n|\\n```$\", \"\", response.content.strip())\n",
    "        refined_queries = json.loads(cleaned)\n",
    "\n",
    "        if not isinstance(refined_queries, list):\n",
    "            raise ValueError(\"ë³´ì • ê²°ê³¼ê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹˜\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"â— ì¿¼ë¦¬ ë³´ì • ì‹¤íŒ¨: {e}\")\n",
    "        refined_queries = original_queries\n",
    "\n",
    "    # ğŸ” ë¡œê·¸ ì¶œë ¥\n",
    "    print(\"\\nğŸ” ì¿¼ë¦¬ ë³´ì • ê²°ê³¼:\")\n",
    "    for o, r in zip(original_queries, refined_queries):\n",
    "        print(f\"- {o} â†’ {r}\")\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"query_list\": refined_queries,\n",
    "        \"previous_query\": original_queries,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6ad462f-65ed-48f6-8f53-833584a16a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë³¸ ë¬¸ì„œ ìˆ˜: 404\n",
      "ì¤‘ë³µ ì œê±° í›„ ë¬¸ì„œ ìˆ˜: 403\n"
     ]
    }
   ],
   "source": [
    "######## nodes.py ########\n",
    "# --- ë¬¸ì„œ ë¡œë“œ ë° ì „ì²˜ë¦¬ ---\n",
    "loader = PyMuPDFLoader(\"stock_report/[ì‚¼ì„±ì „ì]ë¶„ê¸°ë³´ê³ ì„œ(2024.11.14).pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "## : ë¬¸ì„œ ë¶„í• (Split Documents) <-----------ì¶”í›„ ë¬¸ì„œ ì œëª© ë‹¨ìœ„ ë¶„í• ë¡œ ë³€ê²½ í•„ìš”\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=500)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# ì¤‘ë³µ ì œê±°\n",
    "unique_documents = []\n",
    "seen_contents = set()\n",
    "\n",
    "for doc in split_documents:\n",
    "    content = doc.page_content.strip()\n",
    "    if content not in seen_contents:\n",
    "        seen_contents.add(content)\n",
    "        unique_documents.append(doc)\n",
    "\n",
    "print(f\"ì›ë³¸ ë¬¸ì„œ ìˆ˜: {len(split_documents)}\")\n",
    "print(f\"ì¤‘ë³µ ì œê±° í›„ ë¬¸ì„œ ìˆ˜: {len(unique_documents)}\")\n",
    "\n",
    "## ë‹¨ê³„ 3: ì„ë² ë”©(Embedding) ìƒì„±\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# ë²¡í„°ìŠ¤í† ì–´ ìƒì„±\n",
    "vectorstore = Chroma.from_documents(documents=split_documents, embedding=embeddings, persist_directory=\"stock_report/chroma_db\")\n",
    "\n",
    "# 5. ê²€ìƒ‰ê¸°(Retriever) ìƒì„±\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20eb4170-a4d2-48ab-9769-59ad14c08fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_mapping = {\n",
    "    \"ë‹¹ê¸°ìˆœì´ìµ\": \"Net_Income\",\n",
    "    \"ë°œí–‰ì£¼ì‹ìˆ˜\": \"Shares_Outstanding\",\n",
    "    \"í˜„ì¬ ì£¼ê°€\": \"Stock_Price\",\n",
    "    \"ìë³¸ì´ê³„\": \"Shareholders_equity\",\n",
    "    \"ììœ í˜„ê¸ˆíë¦„\": \"Free_cash_flow\",\n",
    "    \"ì˜ì—…ì´ìµ\": \"Operating_income\",\n",
    "    \"ê°€ì¤‘í‰ê· ìë³¸ë¹„ìš©\": \"WACC\",\n",
    "    \"ì˜ˆìƒë¯¸ë˜í˜„ê¸ˆíë¦„\": \"Projected_future_cash_flows\",\n",
    "    \"ì„±ì¥ë¥ \": \"Growth_Rate\",\n",
    "    \"ì£¼ë‹¹ë°°ë‹¹ê¸ˆ\": \"Dividend_per_share\",\n",
    "    \"ê¸°íƒ€ ìˆ˜ìµ ê´€ë ¨ ì •ë³´\": \"Other_return_related_information\",\n",
    "}\n",
    "\n",
    "summary_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "ë‹¹ì‹ ì€ ê¸°ì—…ì˜ ì¬ë¬´ ì •ë³´ë¥¼ ìš”ì•½í•˜ëŠ” ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "ë‹¤ìŒ ë¬¸ì„œë¥¼ ì½ê³ , ì•„ë˜ í•­ëª©ì— ëŒ€í•´ **ì •í™•í•œ ê°’ê³¼ ë‹¨ìœ„**ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.\n",
    "\n",
    "ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš” (JSON):\n",
    "{{\n",
    "  \"ë‹¹ê¸°ìˆœì´ìµ\": \"...\",\n",
    "  \"ë°œí–‰ì£¼ì‹ìˆ˜\": \"...\",\n",
    "  \"í˜„ì¬ ì£¼ê°€\": \"...\",\n",
    "  \"ìë³¸ì´ê³„\": \"...\",\n",
    "  \"ììœ í˜„ê¸ˆíë¦„\": \"...\",\n",
    "  \"ì˜ì—…ì´ìµ\": \"...\",\n",
    "  \"ê°€ì¤‘í‰ê· ìë³¸ë¹„ìš©(WACC)\": \"...\",\n",
    "  \"ì˜ˆìƒë¯¸ë˜í˜„ê¸ˆíë¦„\": \"...\",\n",
    "  \"ì„±ì¥ë¥ \": \"...\",\n",
    "  \"ì£¼ë‹¹ë°°ë‹¹ê¸ˆ\": \"...\",\n",
    "  \"ê¸°íƒ€ ìˆ˜ìµ ê´€ë ¨ ì •ë³´\": \"...\"\n",
    "}}\n",
    "\n",
    "ê°’ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë¬¸ì„œì— ëª…í™•íˆ ì—†ìœ¼ë©´ \"ì—†ìŒ\"ì´ë¼ê³  í‘œê¸°í•˜ì„¸ìš”.\n",
    "\"\"\"),\n",
    "    (\"human\", \"{context}\")\n",
    "])\n",
    "\n",
    "def summarize_context(context: str, llm) -> dict:\n",
    "    messages = summary_prompt.format_messages(context=context)\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    try:\n",
    "        raw = re.sub(r\"^```(?:json)?\\n|\\n```$\", \"\", response.content.strip())\n",
    "        parsed = json.loads(raw)\n",
    "        return {key_mapping.get(k, k): v for k, v in parsed.items()}\n",
    "    except Exception as e:\n",
    "        print(f\"â— ìš”ì•½ íŒŒì‹± ì‹¤íŒ¨: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dd20d91-7758-4168-8e82-072ca9eeb76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(parsed: dict, stock_data: dict):\n",
    "    for k, v in parsed.items():\n",
    "        if k not in stock_data or stock_data[k] == \"ì—†ìŒ\":\n",
    "            stock_data[k] = v\n",
    "\n",
    "def query_loop_node(state: OverallState) -> OverallState:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    tavily = TavilySearchResults(max_results=3)\n",
    "\n",
    "    stock_data = {}\n",
    "    fallback_queries = []\n",
    "    key_fields_to_check = [\"Net_Income\", \"Operating_income\", \"Free_cash_flow\"]\n",
    "\n",
    "    for query in state[\"query_list\"]:\n",
    "        print(f\"\\nğŸ” [RAG ê²€ìƒ‰] {query}\")\n",
    "\n",
    "        try:\n",
    "            docs = list({doc.page_content.strip() for doc in retriever.invoke(query)})\n",
    "            context = \"\\n\\n\".join(docs)[:3000]\n",
    "        except Exception as e:\n",
    "            print(f\"â— RAG ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            context = \"\"\n",
    "\n",
    "        parsed = summarize_context(context, llm)\n",
    "\n",
    "        if all(parsed.get(k, \"ì—†ìŒ\") == \"ì—†ìŒ\" for k in key_fields_to_check):\n",
    "            print(\"âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\")\n",
    "            fallback_queries.append(query)\n",
    "\n",
    "            try:\n",
    "                web_result = tavily.invoke({\"query\": query})\n",
    "\n",
    "                # âœ… ì›¹ ê²°ê³¼ê°€ listì¸ì§€ í™•ì¸\n",
    "                if isinstance(web_result, list):\n",
    "                    web_context = \"\\n\\n\".join([doc.get(\"content\", \"\") for doc in web_result])[:3000]\n",
    "                else:\n",
    "                    web_context = \"\\n\\n\".join([doc.get(\"content\", \"\") for doc in web_result.get(\"documents\", [])])[:3000]\n",
    "\n",
    "                if web_context.strip():\n",
    "                    parsed = summarize_context(web_context, llm)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"â— ì›¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "        # regardless of source (RAG or web), merge\n",
    "        merge(parsed, stock_data)\n",
    "\n",
    "    # ëˆ„ë½ëœ í•­ëª© \"ì—†ìŒ\" ì±„ìš°ê¸°\n",
    "    for key in key_mapping.values():\n",
    "        if key not in stock_data:\n",
    "            stock_data[key] = \"ì—†ìŒ\"\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"Stock_Value_dict\": stock_data,\n",
    "        \"fallback_queries\": fallback_queries,\n",
    "        \"messages\": state[\"messages\"] + [AIMessage(content=\"âœ… í•µì‹¬ í‚¤ ê¸°ì¤€ RAG + ì›¹ fallback ì™„ë£Œ\")],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2600323d-7771-450b-8667-8d92b8213bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_fallback_node(state: OverallState) -> OverallState:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    web = TavilySearchResults(max_results=3)\n",
    "    stock_data = state[\"Stock_Value_dict\"]\n",
    "    fallback_queries = state.get(\"fallback_queries\", [])\n",
    "\n",
    "    for query in fallback_queries:\n",
    "        print(f\"ğŸŒ [ì›¹ ê²€ìƒ‰ fallback] {query}\")\n",
    "        web_result = web.invoke({\"query\": query})\n",
    "        web_context = \"\\n\\n\".join([d[\"content\"] for d in web_result[\"documents\"]])[:3000]\n",
    "        parsed = summarize_context(web_context, llm)\n",
    "        merge(parsed, stock_data)\n",
    "\n",
    "    return {\n",
    "        \"Stock_Value_dict\": stock_data,\n",
    "        \"messages\": state[\"messages\"] + [AIMessage(content=\"ğŸŒ ì›¹ ê²€ìƒ‰ ë³´ì™„ ì™„ë£Œ\")],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ef906d5-a030-4cb8-a7dc-fee97ae0c514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_valuation_node(state: OverallState) -> OverallState:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    financials = state.get(\"Stock_Value_dict\", {})\n",
    "    user_input = state.get(\"user_input\", \"\")\n",
    "\n",
    "    valuation_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"\n",
    "ë‹¹ì‹ ì€ ê¸°ì—…ì˜ ì¬ë¬´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°€ì¹˜ë¥¼ í‰ê°€í•˜ëŠ” ê¸ˆìœµ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ìŒ ì¬ë¬´ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **ì‚¼ì„±ì „ìì˜ ì£¼ì‹ ê°€ì¹˜ë¥¼ ì¶”ì •**í•´ ì£¼ì„¸ìš”.\n",
    "- ê°€ëŠ¥í•˜ë©´ **ììœ í˜„ê¸ˆíë¦„ í• ì¸ë²•(DCF)** ëª¨ë¸ì„ ì‚¬ìš©í•˜ê³ , \n",
    "- **PER/PBR** ê¸°ë°˜ì˜ ë³´ì™„ì  ê³„ì‚°ë„ í•¨ê»˜ ì§„í–‰í•´ ì£¼ì„¸ìš”.\n",
    "\n",
    "ì¶œë ¥ì€ ë‹¤ìŒ í˜•ì‹ì„ ë”°ë¦…ë‹ˆë‹¤:\n",
    "\n",
    "---\n",
    "1. ì‚¬ìš©ëœ ì£¼ìš” ì¬ë¬´ ì§€í‘œ ìš”ì•½\n",
    "2. [DCF] ë°©ì‹ì— ì˜í•œ ì£¼ë‹¹ ì ì • ì£¼ê°€ ì¶”ì •\n",
    "3. [PER/PBR] ë°©ì‹ì— ì˜í•œ ì£¼ë‹¹ ì ì • ì£¼ê°€ ì¶”ì •\n",
    "4. ìµœì¢… íŒë‹¨ ë° íˆ¬ìì ì°¸ê³  ì‚¬í•­\n",
    "\n",
    "ë°ì´í„°:\n",
    "{financials}\n",
    "\"\"\"),\n",
    "        (\"human\", f\"{user_input}ì˜ ì£¼ì‹ ê°€ì¹˜ë¥¼ í‰ê°€í•´ì¤˜.\")\n",
    "    ])\n",
    "\n",
    "    messages = valuation_prompt.format_messages(financials=json.dumps(financials, ensure_ascii=False))\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    print(\"\\nğŸ“ˆ ì£¼ì‹ ê°€ì¹˜ í‰ê°€ ê²°ê³¼:\")\n",
    "    print(response.content.strip())\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"valuation_result\": response.content.strip(),\n",
    "        \"messages\": state[\"messages\"] + [AIMessage(content=\"ğŸ“ˆ ì£¼ì‹ ê°€ì¹˜ í‰ê°€ ì™„ë£Œ\")]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a789c71d-1742-4c8d-81a2-619a6bc789ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë©”ëª¨ë¦¬ ë° ìƒíƒœ ê·¸ë˜í”„ ì´ˆê¸°í™”\n",
    "memory = MemorySaver()\n",
    "graph_builder = StateGraph(OverallState, input=InputState, output=EndState)\n",
    "\n",
    "# ë…¸ë“œ ë“±ë¡\n",
    "graph_builder.add_node(\"User Input\", user_input_node)\n",
    "graph_builder.add_node(\"Search Query Generation\", search_query_generation_node)\n",
    "graph_builder.add_node(\"Query Refinement\", query_refine_node)\n",
    "graph_builder.add_node(\"Query Loop (RAG + Web)\", query_loop_node)\n",
    "graph_builder.add_node(\"Web Fallback\", web_fallback_node)\n",
    "graph_builder.add_node(\"Stock Valuation\", stock_valuation_node)\n",
    "\n",
    "# ì—£ì§€ ì—°ê²°\n",
    "graph_builder.set_entry_point(\"User Input\")  # ì‹œì‘ ë…¸ë“œ\n",
    "graph_builder.add_edge(\"User Input\", \"Search Query Generation\")\n",
    "graph_builder.add_edge(\"Search Query Generation\", \"Query Refinement\")\n",
    "graph_builder.add_edge(\"Query Refinement\", \"Query Loop (RAG + Web)\")\n",
    "graph_builder.add_edge(\"Query Loop (RAG + Web)\", \"Stock Valuation\")\n",
    "graph_builder.add_edge(\"Stock Valuation\", END)\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9ad7c1b-9fd2-4119-988d-8bcbc004f8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================= calculation stock =================================\n",
      "ì£¼ì‹ ê°€ì¹˜ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. ì‚¼ì„±ì „ì ì…ë ¥\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  ì‚¼ì„±ì „\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” ì¿¼ë¦¬ ë³´ì • ê²°ê³¼:\n",
      "- ì‚¼ì„±ì „ì ë‹¹ê¸°ìˆœì´ìµ â†’ ì‚¼ì„±ì „ì 2025ë…„ ì—°ê²° ê¸°ì¤€ ë‹¹ê¸°ìˆœì´ìµ\n",
      "- ì‚¼ì„±ì „ì ë°œí–‰ì£¼ì‹ìˆ˜ â†’ ì‚¼ì„±ì „ì 2025ë…„ ë°œí–‰ì£¼ì‹ìˆ˜\n",
      "- ì‚¼ì„±ì „ì í˜„ì¬ ì£¼ê°€ â†’ ì‚¼ì„±ì „ì 2025ë…„ í˜„ì¬ ì£¼ê°€\n",
      "- ì‚¼ì„±ì „ì ìë³¸ì´ê³„ â†’ ì‚¼ì„±ì „ì 2025ë…„ ì—°ê²° ê¸°ì¤€ ìë³¸ì´ê³„\n",
      "- ì‚¼ì„±ì „ì ììœ í˜„ê¸ˆíë¦„ â†’ ì‚¼ì„±ì „ì 2025ë…„ ììœ í˜„ê¸ˆíë¦„\n",
      "- ì‚¼ì„±ì „ì ì˜ì—…ì´ìµ â†’ ì‚¼ì„±ì „ì 2025ë…„ ì—°ê²° ê¸°ì¤€ ì˜ì—…ì´ìµ\n",
      "- ì‚¼ì„±ì „ì ê°€ì¤‘í‰ê· ìë³¸ë¹„ìš©(WACC) â†’ ì‚¼ì„±ì „ì 2025ë…„ ê°€ì¤‘í‰ê· ìë³¸ë¹„ìš©(WACC)\n",
      "- ì‚¼ì„±ì „ì ì˜ˆìƒë¯¸ë˜í˜„ê¸ˆíë¦„ â†’ ì‚¼ì„±ì „ì 2025ë…„ ì˜ˆìƒ ë¯¸ë˜ í˜„ê¸ˆíë¦„\n",
      "- ì‚¼ì„±ì „ì ì„±ì¥ë¥  â†’ ì‚¼ì„±ì „ì 2025ë…„ ì˜ˆìƒ ì„±ì¥ë¥ \n",
      "- ì‚¼ì„±ì „ì ì£¼ë‹¹ë°°ë‹¹ê¸ˆ â†’ ì‚¼ì„±ì „ì 2025ë…„ ì£¼ë‹¹ë°°ë‹¹ê¸ˆ\n",
      "- ì‚¼ì„±ì „ì ê¸°íƒ€ ìˆ˜ìµ ê´€ë ¨ ì •ë³´ â†’ ì‚¼ì„±ì „ì 2025ë…„ ê¸°íƒ€ ìˆ˜ìµ ê´€ë ¨ ì •ë³´\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì 2025ë…„ ì—°ê²° ê¸°ì¤€ ë‹¹ê¸°ìˆœì´ìµ\n",
      "âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì 2025ë…„ ë°œí–‰ì£¼ì‹ìˆ˜\n",
      "âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì 2025ë…„ í˜„ì¬ ì£¼ê°€\n",
      "âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì 2025ë…„ ì—°ê²° ê¸°ì¤€ ìë³¸ì´ê³„\n",
      "âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì 2025ë…„ ììœ í˜„ê¸ˆíë¦„\n",
      "âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì 2025ë…„ ì—°ê²° ê¸°ì¤€ ì˜ì—…ì´ìµ\n",
      "âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì 2025ë…„ ê°€ì¤‘í‰ê· ìë³¸ë¹„ìš©(WACC)\n",
      "âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì 2025ë…„ ì˜ˆìƒ ë¯¸ë˜ í˜„ê¸ˆíë¦„\n",
      "âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì 2025ë…„ ì˜ˆìƒ ì„±ì¥ë¥ \n",
      "âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì 2025ë…„ ì£¼ë‹¹ë°°ë‹¹ê¸ˆ\n",
      "âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\n",
      "\n",
      "ğŸ” [RAG ê²€ìƒ‰] ì‚¼ì„±ì „ì 2025ë…„ ê¸°íƒ€ ìˆ˜ìµ ê´€ë ¨ ì •ë³´\n",
      "âš ï¸ LLMì´ í•µì‹¬ ê°’ì„ ì¶”ì¶œ ëª»í•¨ â†’ ì›¹ ê²€ìƒ‰ ì‹œë„\n",
      "\n",
      "ğŸ“ˆ ì£¼ì‹ ê°€ì¹˜ í‰ê°€ ê²°ê³¼:\n",
      "---\n",
      "1. ì‚¬ìš©ëœ ì£¼ìš” ì¬ë¬´ ì§€í‘œ ìš”ì•½\n",
      "   - ìˆœì´ìµ(Net Income): 33.62ì–µ ì›\n",
      "   - ë°œí–‰ ì£¼ì‹ ìˆ˜(Shares Outstanding): 6.74ì–µ ì£¼\n",
      "   - í˜„ì¬ ì£¼ê°€(Stock Price): 55,700 ì›\n",
      "   - ìë³¸ì´ê³„(Shareholders' Equity): 4,550,207 ë°±ë§Œ ì›\n",
      "   - ìš´ì˜ ìˆ˜ìµ(Operating Income): 6.6ì¡° ì›\n",
      "   - ë°°ë‹¹ê¸ˆ(Dividend per Share): 363 ì›\n",
      "   - ì„±ì¥ë¥ (Growth Rate): 4.24%\n",
      "   - ì‰ì—¬í˜„ê¸ˆíë¦„: ì—†ìŒ\n",
      "   - ê°€ì¤‘í‰ê· ìë³¸ë¹„ìš©(WACC): ì—†ìŒ\n",
      "   - ê¸°íƒ€: ì—°ê°„ 9.8ì¡° ì› ê·œëª¨ì˜ ì •ê·œ ë°°ë‹¹ ìœ ì§€, ì‰ì—¬í˜„ê¸ˆíë¦„ì˜ 50% ì£¼ì£¼ í™˜ì› ê³„íš\n",
      "\n",
      "2. [DCF] ë°©ì‹ì— ì˜í•œ ì£¼ë‹¹ ì ì • ì£¼ê°€ ì¶”ì •\n",
      "   - í˜„ì¬ ììœ í˜„ê¸ˆíë¦„(Free Cash Flow) ë°ì´í„°ê°€ ì—†ìœ¼ë¯€ë¡œ DCF ëª¨ë¸ì„ ì ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. DCF ëª¨ë¸ì€ ë¯¸ë˜ì˜ ììœ í˜„ê¸ˆíë¦„ì„ ì˜ˆì¸¡í•˜ê³  ì´ë¥¼ í˜„ì¬ ê°€ì¹˜ë¡œ í• ì¸í•˜ì—¬ ì£¼ê°€ë¥¼ ì¶”ì •í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ë”°ë¼ì„œ DCF ë°©ì‹ì— ì˜í•œ ì£¼ê°€ ì¶”ì •ì€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
      "\n",
      "3. [PER/PBR] ë°©ì‹ì— ì˜í•œ ì£¼ë‹¹ ì ì • ì£¼ê°€ ì¶”ì •\n",
      "   - PER(ì£¼ê°€ìˆ˜ìµë¹„ìœ¨) ê³„ì‚°:\n",
      "     - PER = í˜„ì¬ ì£¼ê°€ / ì£¼ë‹¹ ìˆœì´ìµ\n",
      "     - ì£¼ë‹¹ ìˆœì´ìµ(EPS) = ìˆœì´ìµ / ë°œí–‰ ì£¼ì‹ ìˆ˜ = 33.62ì–µ ì› / 6.74ì–µ ì£¼ = ì•½ 4,980 ì›\n",
      "     - PER = 55,700 ì› / 4,980 ì› â‰ˆ 11.17\n",
      "\n",
      "   - PBR(ì£¼ê°€ìˆœìì‚°ë¹„ìœ¨) ê³„ì‚°:\n",
      "     - PBR = í˜„ì¬ ì£¼ê°€ / ì£¼ë‹¹ ìˆœìì‚°\n",
      "     - ì£¼ë‹¹ ìˆœìì‚°(BPS) = ìë³¸ì´ê³„ / ë°œí–‰ ì£¼ì‹ ìˆ˜ = 4,550,207 ë°±ë§Œ ì› / 6.74ì–µ ì£¼ = ì•½ 67,500 ì›\n",
      "     - PBR = 55,700 ì› / 67,500 ì› â‰ˆ 0.82\n",
      "\n",
      "   - PER ê¸°ë°˜ì˜ ì ì • ì£¼ê°€ ì¶”ì •:\n",
      "     - PERì˜ í‰ê· ê°’ì„ 15ë¡œ ê°€ì •í•  ê²½ìš°, ì ì • ì£¼ê°€ëŠ” EPS * PER = 4,980 ì› * 15 = 74,700 ì›\n",
      "\n",
      "   - PBR ê¸°ë°˜ì˜ ì ì • ì£¼ê°€ ì¶”ì •:\n",
      "     - PBRì˜ í‰ê· ê°’ì„ 1.5ë¡œ ê°€ì •í•  ê²½ìš°, ì ì • ì£¼ê°€ëŠ” BPS * PBR = 67,500 ì› * 1.5 = 101,250 ì›\n",
      "\n",
      "4. ìµœì¢… íŒë‹¨ ë° íˆ¬ìì ì°¸ê³  ì‚¬í•­\n",
      "   - DCF ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ PER ë° PBR ê¸°ë°˜ì˜ ì¶”ì •ì¹˜ë¥¼ í†µí•´ ì‚¼ì„±ì „ìì˜ ì£¼ê°€ë¥¼ í‰ê°€í–ˆìŠµë‹ˆë‹¤.\n",
      "   - PER ê¸°ë°˜ì˜ ì ì • ì£¼ê°€ëŠ” ì•½ 74,700 ì›, PBR ê¸°ë°˜ì˜ ì ì • ì£¼ê°€ëŠ” ì•½ 101,250 ì›ìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.\n",
      "   - í˜„ì¬ ì£¼ê°€ëŠ” 55,700 ì›ìœ¼ë¡œ, ë‘ ê°€ì§€ ë°©ë²• ëª¨ë‘ í˜„ì¬ ì£¼ê°€ë³´ë‹¤ ë†’ì€ ì ì • ì£¼ê°€ë¥¼ ì œì‹œí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì‚¼ì„±ì „ìì˜ ì£¼ì‹ì´ í˜„ì¬ ì €í‰ê°€ë˜ì–´ ìˆì„ ê°€ëŠ¥ì„±ì„ ì‹œì‚¬í•©ë‹ˆë‹¤.\n",
      "   - ê·¸ëŸ¬ë‚˜, ììœ í˜„ê¸ˆíë¦„ ë°ì´í„°ê°€ ì—†ê³ , WACCì™€ ê°™ì€ ì¤‘ìš”í•œ ì§€í‘œê°€ ê²°ì—¬ë˜ì–´ ìˆì–´ ë³´ë‹¤ ì •í™•í•œ í‰ê°€ë¥¼ ìœ„í•´ ì¶”ê°€ì ì¸ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤. íˆ¬ì ê²°ì •ì„ ë‚´ë¦¬ê¸° ì „ì— ì¶”ê°€ì ì¸ ë¶„ì„ê³¼ ì‹œì¥ ë™í–¥ì„ ê³ ë ¤í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ì´ˆê¸° ìƒíƒœ\n",
    "initial_state = {\n",
    "    \"start_input\": \"\",\n",
    "}\n",
    "\n",
    "# ê·¸ë˜í”„ ì‹¤í–‰\n",
    "final_state = graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127f08a0-5d6e-4fe0-bb84-7619c0ebba63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
